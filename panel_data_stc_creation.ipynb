{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter species shortname (e.g., phrag): phrag\n"
     ]
    }
   ],
   "source": [
    "import arcpy\n",
    "from arcpy import env\n",
    "arcpy.env.workspace = r'C:\\Users\\ltmsbi\\Documents\\ArcGIS\\Projects\\Final_Deployment\\Final_Deployment.gdb'\n",
    "arcpy.env.OverwriteOutput = True\n",
    "species = input(\"Enter species shortname (e.g., phrag): \")\n",
    "threshold = \"precision\"\n",
    "presence_feature = \"SVI_Project_presences_\"+species+\"_\"+threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add & calculate new date field\n",
    "def add_formatted_date_field(feature):\n",
    "    arcpy.management.AddField(feature, \"date_formatted\", \"DATE\", field_alias=\"date_formatted\")\n",
    "    arcpy.management.CalculateField(feature, \"date_formatted\", \"!date!\")\n",
    "\n",
    "add_formatted_date_field(presence_feature)\n",
    "add_formatted_date_field(\"pred_finalDeployment_all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>Output</h2>C:\\Users\\ltmsbi\\Documents\\ArcGIS\\Projects\\Final_Deployment\\Final_Deployment.gdb\\SVI_Proj_panel_data_precision_phrag<h2>Messages</h2>Start Time: Tuesday, May 16, 2023 3:27:39 PM<br/>Succeeded at Tuesday, May 16, 2023 3:27:41 PM (Elapsed Time: 2.43 seconds)<br/><style>.rendered_html td, .rendered_html th {text-align: left;}.rendered_html tbody {border: 1px solid black;}</style>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Users\\\\ltmsbi\\\\Documents\\\\ArcGIS\\\\Projects\\\\Final_Deployment\\\\Final_Deployment.gdb\\\\SVI_Proj_panel_data_precision_phrag'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spatial join n years of presences to distinct layers\n",
    "\n",
    "# Define field mappings to keep only the target layer's fields\n",
    "def create_SJ_field_mappings(targetLayer, joinLayer): # Return field mappings for spatial joins when called \n",
    "    \n",
    "    # List starting fields for spatial joins that'll be updated with each successive join\n",
    "    keepFields = list()\n",
    "    omitFields = [\"OBJECTID\", \"Shape\", \"Shape_Area\", \"Shape_Length\"]\n",
    "    for field in arcpy.ListFields(targetLayer):\n",
    "        if field.name not in omitFields:\n",
    "            keepFields.append(field.name)\n",
    "    fieldMappings = arcpy.FieldMappings() # field mapping variable; this will store all field mappings\n",
    "    # Create list of field names to keep in the output file\n",
    "    targetTable = []\n",
    "    for i in arcpy.ListFields(targetLayer):\n",
    "        if i.name in (keepFields):\n",
    "            targetTable.append(i.name)\n",
    "    # List of input feature classes for the spatial join\n",
    "    f = [targetLayer, joinLayer]\n",
    "    # loop through main table\n",
    "    for k in targetTable: \n",
    "        #print(\"Field: \",k)\n",
    "        fieldMap = arcpy.FieldMap() # create an empty field map variable\n",
    "        fieldMap.addInputField(targetLayer,k) # insert the target layer as the first input into the field map\n",
    "        for feature in f: # loop through feature classes\n",
    "            for field in arcpy.ListFields(feature): # loop through field of each feature class\n",
    "                if k in field.name: # check if any field matches with our target field then append it as an input field\n",
    "                    fieldMap.addInputField(feature,field.name) \n",
    "        fieldMappings.addFieldMap(fieldMap) # add the current field map to the main field map variable\n",
    "    return(fieldMappings)\n",
    "# Get range of presence dates for which to run spatial joins\n",
    "def year_range(presences):\n",
    "    import datetime\n",
    "    import time\n",
    "    listDates = []\n",
    "    cursor = arcpy.da.SearchCursor(presences, field_names=\"date_formatted\")\n",
    "    for row in cursor:\n",
    "        listDates.append(row)\n",
    "    # Get max and min datetime objects, isolate year as integer\n",
    "    max_date = max(listDates)[0].year\n",
    "    min_date = min(listDates)[0].year\n",
    "    year_range = [min_date,max_date+1]\n",
    "    return year_range\n",
    "\n",
    "year_range = year_range(presence_feature)\n",
    "panel_features = list()\n",
    "hex_grid = \"SVI_Proj_hex_grid_\"+species\n",
    "\n",
    "for year in range(year_range[0],year_range[1]):\n",
    "    time_clause = \"date_formatted >= timestamp '\"+str(year)+\"-01-01 00:00:00' And date_formatted <= timestamp '\"+str(year)+\"-12-31 23:59:59'\"\n",
    "    # Join year's model pano count to hex grid\n",
    "    pano_points = arcpy.management.SelectLayerByAttribute(\"pred_finalDeployment_all\", \"NEW_SELECTION\", time_clause)\n",
    "    hex_grid_SJ = \"tmp_hex_\"+str(year)\n",
    "    fm = create_SJ_field_mappings(hex_grid, pano_points) # May need to delete some fields here\n",
    "    arcpy.analysis.SpatialJoin(hex_grid, pano_points, hex_grid_SJ, field_mapping=fm)\n",
    "    del fm\n",
    "    arcpy.management.DeleteField(hex_grid_SJ, \"TARGET_FID\")\n",
    "    arcpy.management.AlterField(hex_grid_SJ, \"JOIN_COUNT\", \"model_points\", \"model_points\")\n",
    "    # Isolate year's presences as join layer\n",
    "    join_layer = arcpy.management.SelectLayerByAttribute(presence_feature, \"NEW_SELECTION\", time_clause)\n",
    "    # Spatial join model data and presences\n",
    "    fm = create_SJ_field_mappings(hex_grid_SJ, join_layer)\n",
    "    tmp_join = \"SJ_\"+species+\"_\"+threshold+\"_\"+str(year)\n",
    "    arcpy.analysis.SpatialJoin(hex_grid_SJ, join_layer, tmp_join, field_mapping=fm)\n",
    "    # Add & assign timestamp\n",
    "    d_field = \"date\"\n",
    "    arcpy.management.AddField(tmp_join, d_field, \"DATE\", field_alias=d_field)\n",
    "    arcpy.management.CalculateField(tmp_join, d_field, \"'\"+str(year)+\"-01-01 12:00:00 AM'\")\n",
    "    # Add & calculate prevalence\n",
    "    prev_field = species+\"_prev\"\n",
    "    arcpy.management.AddField(tmp_join, prev_field, \"FLOAT\", field_alias=prev_field)\n",
    "    arcpy.management.CalculateField(tmp_join, prev_field, \"!JOIN_COUNT!/!model_points!\")\n",
    "    # Add field for filling later\n",
    "    prev_field_filled = species+\"_prev_fill\"\n",
    "    arcpy.management.AddField(tmp_join, prev_field_filled, \"FLOAT\", field_alias=prev_field_filled)\n",
    "    # Delete JOIN_COUNT, and yearly pano count fields\n",
    "    # arcpy.management.DeleteField(in_table=tmp_join,drop_field=['JOIN_COUNT','model_points'])\n",
    "    # Append layer to panel features for merging later\n",
    "    panel_features.append(tmp_join)\n",
    "    arcpy.management.SelectLayerByAttribute(presence_feature, \"CLEAR_SELECTION\")\n",
    "    del time_clause, join_layer, fm, tmp_join, d_field, prev_field\n",
    "\n",
    "# Merge into one feature for filling and conversion to netCDF\n",
    "panel_data_unfilled = \"SVI_Proj_panel_data_\"+threshold+\"_\"+species+\"_unfilled\"\n",
    "arcpy.management.Merge(panel_features, panel_data_unfilled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prevalence values filled\n",
      "Panel feature class created\n",
      "Space-time cube complete\n"
     ]
    }
   ],
   "source": [
    "panel_data_unfilled = \"SVI_Proj_panel_data_\"+threshold+\"_\"+species+\"_unfilled\"\n",
    "# Fill zero prevalence values with last nonzero value\n",
    "\n",
    "# Convert panel features to pandas sedf\n",
    "import pandas as pd\n",
    "from arcgis.features import GeoAccessor, GeoSeriesAccessor\n",
    "unfilled_sedf = pd.DataFrame.spatial.from_featureclass(panel_data_unfilled)\n",
    "# Sort by two columns to make sure the time step \n",
    "# ids are in order based on location id\n",
    "unfilled_sedf.sort_values(by=[\"GRID_ID\", \"date\"],\n",
    "                          ascending = [True, True],\n",
    "                          inplace=True)\n",
    "# Define and apply function to fill zeroes with last nonzero value\n",
    "def fill_values(df):\n",
    "    new_parr = []\n",
    "    fill = 0\n",
    "    # Return the sum of pano join count for the current Location ID\n",
    "    count_sum = df['model_points'].sum()\n",
    "    for val in df[species+\"_prev\"]:\n",
    "        if count_sum == 0:\n",
    "            fill = np.nan\n",
    "        elif count_sum > 0:\n",
    "            # Set the fill value to be the last positive value encountered\n",
    "            if val > 0:\n",
    "                fill = val\n",
    "        else:\n",
    "            pass\n",
    "        new_parr.append(fill)\n",
    "    df[species+\"_prev\"] = new_parr\n",
    "    return df\n",
    "filled_sedf = unfilled_sedf.groupby('GRID_ID').apply(fill_values)\n",
    "#filled_sedf.iloc[0:50,:]\n",
    "print(\"Prevalence values filled\")\n",
    "# Convert back to feature class\n",
    "panel_data_filled = arcpy.env.workspace+r'\\SVI_Proj_panel_data_'+threshold+\"_\"+species\n",
    "filled_sedf.spatial.to_featureclass(panel_data_filled)\n",
    "print(\"Panel feature class created\")\n",
    "# Convert to netCDF that's ready for emerging hotspot analysis\n",
    "arcpy.stpm.CreateSpaceTimeCubeDefinedLocations(in_features=panel_data_filled, \n",
    "                                               output_cube='SVI_Proj_panel_cube_'+threshold+\"_\"+species, \n",
    "                                               location_id='target_fid', \n",
    "                                               temporal_aggregation='NO_TEMPORAL_AGGREGATION', \n",
    "                                               time_field='date',\n",
    "                                               time_step_interval='1 Years',\n",
    "                                               variables=[[species+'_prev','DROP_LOCATIONS']]\n",
    "                                              )\n",
    "print(\"Space-time cube complete and located in project folder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COUNT</th>\n",
       "      <th>date</th>\n",
       "      <th>Location ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    COUNT  date  Location ID\n",
       "0     0.0     1            1\n",
       "1     1.0     2            1\n",
       "2     1.0     3            1\n",
       "3     5.0     4            1\n",
       "4     0.0     1            2\n",
       "5     2.0     2            2\n",
       "6     2.0     3            2\n",
       "7     2.0     4            2\n",
       "8     NaN     1            3\n",
       "9     NaN     2            3\n",
       "10    NaN     3            3\n",
       "11    NaN     4            3"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Proof-of-concept for filling behavior\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "d = {'COUNT': [ 0, 1, 0, 5, 0 , 2 , 0, 0 ,  0,  0,  0,  0], \n",
    "     'date': [1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4], \n",
    "     'Location ID': [1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3]\n",
    "    }\n",
    "df = pd.DataFrame(data=d)\n",
    "def fill_values(small_df):\n",
    "    new_parr = []\n",
    "    fill = 0\n",
    "    # Return the sum of values for the current Location ID\n",
    "    count_sum = small_df['COUNT'].sum()\n",
    "    # Fill values according to logic\n",
    "    for val in small_df['COUNT']:\n",
    "        if count_sum == 0:\n",
    "            fill = np.nan\n",
    "        elif count_sum > 0:\n",
    "            # Set the fill value to be the last positive value encountered\n",
    "            if val > 0:\n",
    "                fill = val\n",
    "        else:\n",
    "            pass\n",
    "        new_parr.append(fill)\n",
    "    small_df[\"COUNT\"] = new_parr\n",
    "    return small_df\n",
    "# Apply the fill_values function to each Location ID group.\n",
    "# Applied in this way, the function fills NaN values in locations \n",
    "# with only zero values for COUNT (i.e., locations with no panoramas\n",
    "# assessed during any timestep). It fills empty COUNT timesteps with \n",
    "# the last positive value for locations with any positive values, or \n",
    "# zero if there had not yet been any positive values (i.e., panoramas \n",
    "# assessed)\n",
    "result = df.groupby('Location ID').apply(fill_values)\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
