{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nReporting Gap Analysis\\nAuthor: Liam Megraw, RIT Envirionmental Science Technician\\nDate last edited: 7/19/2023\\nESRI ArcGIS Pro Version 2.7\\nDefault Python 3.x kernel\\n\\nDescription:\\nThis code processes uses results from the RIT-developed computer \\nvision model and iMapInvasives records to identify gaps in reporting\\non a per-species basis. The first part compares all iMap and model \\nrecords for the species of interest at the same time, while the \\nsecond part compares them on a per-species basis.\\n\\nInputs required, stored in one geodatabase at the same projected coordinate reference system (CRS):\\n> Single point dataset of model prediction points with n species each\\n  having their own confidence score column (name must be input two cells below)\\n> 1 km grid for aoi named \"reporting_analysis_grid_empty\" (or alternatively \\ncreated by uncommenting the 6th notebook cell)\\n> 7 iMapInvasives datasets for n species (name should follow default \\nconvention in all caps below)\\n    > PRESENCE_POINT (confirmed) \\n    > PRESENCE_LINE (confirmed)\\n    > PRESENCE_POLYGON (confirmed)\\n    > PRESENCE_POINT_UNCONFIRMED\\n    > PRESENCE_LINE_UNCONFIRMED\\n    > PRESENCE_POLYGON_UNCONFIRMED\\n    > NOT_DETECTED_POLYGON\\n> n point datasets of model presence predictions at a threshold for \\nthe per-species approach. The name should follow this convention: \\nSVI_Project_presences_species_threshold. For example, \\nSVI_Project_presences_phrag_precision. Species names need to match \\nthe shortnames in the dictionary in notebook cell 4.\\n\\nScaling:\\nIf the model is expanded to additional species, they will have to be \\nadded into the dictionary in cell 4. If these additional species have \\nlimited date ranges where results should be interpreted, that exception \\nwill need to be added into the date constraint dictionary in cell 4.\\n\\nOutputs:\\nThe final outputs are two polygon layers at a 1 km resolution with \\noverall and per-species attributes detailing the type of records \\nwithin a cell (model only, iMap only, or both), and if there is \\noverlap, a comparison value between the two types of records.\\n\\nHow to Use:\\nThese layers can be hosted on the ArcGIS Online Public and Manager Dashboards.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Reporting Gap Analysis\n",
    "Author: Liam Megraw, RIT Envirionmental Science Technician\n",
    "Date last edited: 7/20/2023\n",
    "ESRI ArcGIS Pro Version 2.7\n",
    "Default Python 3.x kernel\n",
    "\n",
    "Description:\n",
    "This code processes uses results from the RIT-developed computer \n",
    "vision model and iMapInvasives records to identify gaps in reporting\n",
    "on a per-species basis. The first part compares all iMap and model \n",
    "records for the species of interest at the same time, while the \n",
    "second part compares them on a per-species basis.\n",
    "\n",
    "Inputs required, stored in one geodatabase at the same projected coordinate reference system (CRS):\n",
    "> Single point dataset of model prediction points with n species each\n",
    "  having their own confidence score column (name must be input two cells below)\n",
    "> 1 km grid for aoi named \"reporting_analysis_grid_empty\" (or alternatively \n",
    "created by uncommenting the 6th notebook cell)\n",
    "> 7 iMapInvasives datasets for n species (name should follow default \n",
    "convention in all caps below)\n",
    "    > PRESENCE_POINT (confirmed) \n",
    "    > PRESENCE_LINE (confirmed)\n",
    "    > PRESENCE_POLYGON (confirmed)\n",
    "    > PRESENCE_POINT_UNCONFIRMED\n",
    "    > PRESENCE_LINE_UNCONFIRMED\n",
    "    > PRESENCE_POLYGON_UNCONFIRMED\n",
    "    > NOT_DETECTED_POLYGON\n",
    "> n point datasets of model presence predictions at a threshold for \n",
    "the per-species approach. The name should follow this convention: \n",
    "SVI_Project_presences_species_threshold. For example, \n",
    "SVI_Project_presences_phrag_precision. Species names need to match \n",
    "the shortnames in the dictionary in notebook cell 4.\n",
    "\n",
    "Scaling:\n",
    "If the model is expanded to additional species, they will have to be \n",
    "added into the dictionary in cell 4. If these additional species have \n",
    "limited date ranges where results should be interpreted, that exception \n",
    "will need to be added into the date constraint dictionary in cell 4.\n",
    "\n",
    "Outputs:\n",
    "The final outputs are two polygon layers at a 1 km resolution with \n",
    "overall and per-species attributes detailing the type of records \n",
    "within a cell (model only, iMap only, or both), and if there is \n",
    "overlap, a comparison value between the two types of records.\n",
    "\n",
    "How to Use:\n",
    "These layers can be hosted on the ArcGIS Online Public and Manager Dashboards.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPseudocode Overview\\n\\nAssign workspace and input files/parameters\\nCreate lists of input files\\n    iMap: point, line, polygon\\n    model: point\\nDefine function to create field mappings for spatial joins\\n(Optionally) create state-wide fishnets at 1 km resolution\\n\\nThresholdless approach\\n    Effectively, for both model data and iMap data, and each imap geometry type:\\n            Spatial join records to fishnet\\n            Add & calculate fields\\n                Total join count for that species\\n                Overlap type if statement:\\n                    Cells where model data join count is above zero and iMap join count above zero: both (i.e., overlap)\\n                    Cells where model data join count is above zero and iMap join count is zero: (i.e, model only)\\n                    Cells where model data join count is zero and iMap join count is above zero (i.e., iMap only)\\n                Calculate comparison between model and iMap\\nThresholded (per-species) approach\\n    For each species:\\n        Export iMap records to layers split by species, record type, and geometry\\n        Spatially join records to fishnet\\n        Calculate ratios and percentiles for each comparison type\\nExport results\\n\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Pseudocode Overview\n",
    "\n",
    "Assign workspace and input files/parameters\n",
    "Create lists of input files\n",
    "    iMap: point, line, polygon\n",
    "    model: point\n",
    "Define function to create field mappings for spatial joins\n",
    "(Optionally) create state-wide fishnets at 1 km resolution\n",
    "\n",
    "Thresholdless approach\n",
    "    Effectively, for both model data and iMap data, and each imap geometry type:\n",
    "            Spatial join records to fishnet\n",
    "            Add & calculate fields\n",
    "                Total join count for that species\n",
    "                Overlap type if statement:\n",
    "                    Cells where model data join count is above zero and iMap join count above zero: both (i.e., overlap)\n",
    "                    Cells where model data join count is above zero and iMap join count is zero: (i.e, model only)\n",
    "                    Cells where model data join count is zero and iMap join count is above zero (i.e., iMap only)\n",
    "                Calculate comparison between model and iMap\n",
    "Thresholded (per-species) approach\n",
    "    For each species:\n",
    "        Export iMap records to layers split by species, record type, and geometry\n",
    "        Spatially join records to fishnet\n",
    "        Calculate ratios and percentiles for each comparison type\n",
    "Export results\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter absolute geodatabase path: C:\\Users\\ltmsbi\\Documents\\ArcGIS\\Projects\\Final_Deployment\\Final_Deployment.gdb\n",
      "Enter model prediction dataset name: pred_finalDeployment_all\n",
      "Enter threshold name (all lowercase): precision\n",
      "Do you have a reporting analysis grid feature? (y/n):y\n",
      "Is your grid named 'reporting_analysis_grid_empty'? (y/n): y\n",
      "Empty reporting grid name: reporting_analysis_grid_empty\n"
     ]
    }
   ],
   "source": [
    "# #----- Get and set workspace to gdb -----\n",
    "import arcpy\n",
    "from arcpy import env\n",
    "import os\n",
    "def set_workspace():\n",
    "    while True:\n",
    "        gdb = input('Enter absolute geodatabase path: ')\n",
    "        if os.path.exists(gdb):\n",
    "            return gdb\n",
    "        else:\n",
    "            print(\"Geodatabase path incorrect\")\n",
    "    \n",
    "arcpy.env.workspace = set_workspace()\n",
    "cws = arcpy.env.workspace\n",
    "arcpy.env.OverwriteOutput = True\n",
    "\n",
    "def assign_layer_name(prompt):\n",
    "   cws = arcpy.env.workspace\n",
    "   while True:\n",
    "      layer_name = input(prompt)\n",
    "      if arcpy.Exists(os.path.join(cws, layer_name)):\n",
    "         return layer_name\n",
    "      else:\n",
    "         print(\"No file of this name exists in your geodatabase, please verify.\")\n",
    "\n",
    "# Define necessary input files\n",
    "# Each species must have their own column, named according to the dictionary in the cell below\n",
    "\n",
    "model_pred = assign_layer_name(prompt=\"Enter model prediction dataset name: \")\n",
    "\n",
    "# The value is used as a suffix and as a field in \n",
    "# the final per-species viewing layer\n",
    "threshold = input('Enter threshold name (all lowercase): ')\n",
    "\n",
    "def check_rag():\n",
    "    rag_exist = input(\"Do you have a reporting analysis grid feature? (y/n):\")\n",
    "    if rag_exist == \"y\":\n",
    "        def name_rag():\n",
    "            default_choice = input(\"Is your grid named 'reporting_analysis_grid_empty'? (y/n): \")\n",
    "            if default_choice == \"y\":\n",
    "                rag_initial = 'reporting_analysis_grid_empty'\n",
    "                if arcpy.Exists(os.path.join(cws, rag_initial)):\n",
    "                    return rag_initial\n",
    "                else:\n",
    "                    print(\"No file of this name exists in your geodatabase; please verify.\")\n",
    "                    name_rag()\n",
    "            elif default_choice == \"n\":\n",
    "                rag_initial = input(\"Enter reporting grid name: \")\n",
    "                if arcpy.Exists(os.path.join(cws, rag_initial)):\n",
    "                    return rag_initial\n",
    "                else:\n",
    "                    print(\"No file of this name exists in your geodatabase; please verify.\")\n",
    "                    name_rag()\n",
    "            else:\n",
    "                print(\"Incorrect entry, please try again\")\n",
    "                name_rag()\n",
    "        return name_rag()\n",
    "    elif rag_exist == \"n\":\n",
    "        print(\"Use the 'create fishnet' tool to create a grid for your aoi and then re-run this code.\")\n",
    "    else:\n",
    "        print(\"Incorrect entry, please try again\")\n",
    "        check_rag()\n",
    "\n",
    "rag_empty = check_rag()\n",
    "print(\"Empty reporting grid name:\", rag_empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary of long names\n",
    "# Names used for filtering in ArcGIS Online\n",
    "species_fullnames = {\n",
    "    \"phrag\": \"'Phragmites, Unspecified'\", # extra sinlge quotes are intentional since these are used in a field calculation\n",
    "    \"knot\": \"'Knotweed, Unspecified'\",\n",
    "    \"wp\": \"'Wild Parsnip'\",\n",
    "    \"toh\": \"'Tree-of-Heaven (Ailanthus)'\",\n",
    "    \"pl\": \"'Purple Loosestrife'\"\n",
    "}\n",
    "\n",
    "# Extract only the keys to a list\n",
    "species_shortnames = list(species_fullnames.keys())\n",
    "\n",
    "# List shortnames of species and their date constraints\n",
    "date_constraint_where_clauses = {\n",
    "    \"wp\": \"date LIKE '%-05' Or date LIKE '%-06' Or date LIKE '%-07'\",\n",
    "    \"toh\": \"date LIKE '%-07' Or date LIKE '%-08' Or date LIKE '%-09' Or date LIKE '%-10'\",\n",
    "    \"pl\": \"date LIKE '%-07' Or date LIKE '%-08' Or date LIKE '%-09' Or date LIKE '%-10'\"\n",
    "}\n",
    "date_constrained_species = list(date_constraint_where_clauses.keys())\n",
    "\n",
    "# IDs that iMap assigns to the various species of interest\n",
    "jurisdiction_ids = {\n",
    "    \"phrag\": 1277,\n",
    "    \"wp\": 1182,\n",
    "    \"pl\": 1265,\n",
    "    \"toh\": 1167,\n",
    "    \"knot\": (1074, 1191, 1278, 1479) # Includes Japanese knotweed, giant knotweed, bohemian knotweed, and knotweed species unknown\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for use in one or both layers\n",
    "\n",
    "def create_SJ_FieldMappings(targetLayer, joinLayer): # Return field mappings for spatial joins when called \n",
    "    \n",
    "    # List starting fields for spatial joins that'll be updated with each successive join\n",
    "    keepFields = list()\n",
    "    omitFields = [\"OBJECTID\", \"Shape\", \"Shape_Area\", \"Shape_Length\"]\n",
    "\n",
    "    for field in arcpy.ListFields(targetLayer):\n",
    "        if field.name not in omitFields:\n",
    "            keepFields.append(field.name)\n",
    "    fieldMappings = arcpy.FieldMappings() # Create field mapping variable; this will store all field mappings\n",
    "\n",
    "    # Create list of field names to keep in the output file\n",
    "    targetTable = []\n",
    "    for i in arcpy.ListFields(targetLayer):\n",
    "        if i.name in (keepFields):\n",
    "            targetTable.append(i.name)\n",
    "\n",
    "    # List of input feature classes for the spatial join\n",
    "    f = [targetLayer, joinLayer]\n",
    "\n",
    "    for k in targetTable: # loop through main table\n",
    "        #print(\"Field: \",k)\n",
    "        fieldMap = arcpy.FieldMap() # create an empty field map variable\n",
    "        fieldMap.addInputField(targetLayer,k) # insert the target layer as the first input into the field map\n",
    "        for feature in f: # loop through feature classes\n",
    "            for field in arcpy.ListFields(feature): # loop through field of each feature class\n",
    "                if k in field.name: # check if any field matches with our target field then append it as an input field\n",
    "                    fieldMap.addInputField(feature,field.name) \n",
    "        fieldMappings.addFieldMap(fieldMap) # add the current field map to the main field map variable\n",
    "    return(fieldMappings)\n",
    "\n",
    "def generate_where_clauses(type, species=\"\"): # Return a dictionary of where clauses to select records for calculations when called \n",
    "    if type == \"THRESHOLDED\":\n",
    "        l_suffix = \"_\"+species\n",
    "        points = \"model\"+l_suffix\n",
    "        extras = [\"\",\")\"]\n",
    "    elif type == \"NOT_THRESHOLDED\":\n",
    "        l_suffix = \"\"\n",
    "        points = \"model_points\"\n",
    "        extras = [\" And imap_nd = 0\", \" Or imap_nd > 0)\"]\n",
    "\n",
    "    iMap_cnfrm = \"imap_cnfrm\"+l_suffix\n",
    "    iMap_uncnfrm = \"imap_uncnfrm\"+l_suffix\n",
    "    iMap_nd = \"imap_nd\"+l_suffix\n",
    "    # Handle exception for species with date-constrained panorama interpretation\n",
    "    if species in date_constrained_species:\n",
    "        model_points = \"model_\"+species+\"_possible\"\n",
    "    else:\n",
    "        model_points = \"model_points\"\n",
    "    model_positives = \"model\"+l_suffix # Unused name in the thresholdless version\n",
    "\n",
    "    whereClauses = { # Define SQL queries used to select records\n",
    "                # These will be set to negative integers\n",
    "                \"model-only_conf\": points+\" > 0 And \"+iMap_cnfrm+\" = 0\"+extras[0], \n",
    "                \"model-only_unconf\": points+\" > 0 And \"+iMap_cnfrm+\" = 0 And \"+iMap_uncnfrm+\" = 0\"+extras[0],\n",
    "                # These will be set to 0\n",
    "                \"iMap-only_conf\": points+\" = 0 And (\"+iMap_cnfrm+\" > 0\"+extras[1], \n",
    "                \"iMap-only_unconf\": points+\" = 0 And (\"+iMap_cnfrm+\" > 0 Or \"+iMap_uncnfrm+\" > 0\"+extras[1],\n",
    "                # These will be set to positive floats\n",
    "                \"Overlap_conf\": points+\" > 0 And (\"+iMap_cnfrm+\" > 0\"+extras[1], \n",
    "                \"Overlap_unconf\": points+\" > 0 And (\"+iMap_cnfrm+\" > 0 Or \"+iMap_uncnfrm+\" > 0\"+extras[1],\n",
    "                # Cells with neither record type will retain a null designation during calculation\n",
    "                }\n",
    "\n",
    "    if type == \"THRESHOLDED\": # Add extra conditions\n",
    "        whereClauses[\"model-only_nd\"] = model_points+\" > 0 And \"+model_points+\" >= \"+model_positives+\" And \"+iMap_nd+\" = 0\"\n",
    "        whereClauses[\"iMap-only_nd\"] = model_points+\" = 0 And \"+iMap_nd+\" > 0\"\n",
    "        whereClauses[\"Overlap_nd\"] = model_points+\" > 0 And \"+model_points+\" >= \"+model_positives+\" And \"+iMap_nd+\" > 0\"\n",
    "    \n",
    "    return(whereClauses) # Return dictionary of where clauses when called\n",
    "\n",
    "def generate_calc_field_dict(type, species=\"\"): # Return a dictionary of fields to assign calculated value \n",
    "    fields_dict = generate_where_clauses(type, species) # Create a reference to the whereClause dict\n",
    "    \n",
    "    # Update dict entries with the fields where future-calculated values should be stored\n",
    "    if type == \"THRESHOLDED\":\n",
    "        s_suffix = \"_\"+species\n",
    "        for field in [\"model-only_nd\", \"iMap-only_nd\", \"Overlap_nd\"]:\n",
    "            fields_dict[field] = \"NDc\"+s_suffix\n",
    "    elif type == \"NOT_THRESHOLDED\":\n",
    "        s_suffix = \"_overall\"\n",
    "    for field in [\"model-only_conf\", \"iMap-only_conf\", \"Overlap_conf\"]:\n",
    "        fields_dict[field] = \"Cc\"+s_suffix\n",
    "    for field in [\"model-only_unconf\", \"iMap-only_unconf\", \"Overlap_unconf\"]:\n",
    "        fields_dict[field] = \"CUc\"+s_suffix\n",
    "    \n",
    "    return(fields_dict)\n",
    "\n",
    "def generate_calc_expressions(type, species=\"\"): # Return a dictionary of expressions to calculate comparison values \n",
    "    exp_dict = generate_where_clauses(type, species) # Create reference to main whereClause dict\n",
    "    \n",
    "    if type == \"THRESHOLDED\":\n",
    "        l_suffix = \"_\"+species\n",
    "        points = \"!model\"+l_suffix+\"!\"\n",
    "        extra = \"\"\n",
    "        model_positives = \"!model\"+l_suffix+\"!\"\n",
    "        if species in date_constrained_species:\n",
    "            model_possible = \"!model_\"+species+\"_possible!\"\n",
    "        else:\n",
    "            model_possible = \"!model_points!\"\n",
    "    elif type == \"NOT_THRESHOLDED\":\n",
    "        l_suffix = \"\"\n",
    "        points = \"!model_points!\"\n",
    "        extra = \"+ !imap_nd!\"\n",
    "        \n",
    "    # Generate proper layer names to reference in calculations \n",
    "    iMap_cnfrm = \"!imap_cnfrm\"+l_suffix+\"!\"\n",
    "    iMap_uncnfrm = \"!imap_uncnfrm\"+l_suffix+\"!\"\n",
    "    iMap_nd = \"!imap_nd\"+l_suffix+\"!\"\n",
    "        \n",
    "\n",
    "    # Update dictionary with the values being the expression used to calculate the field determined by generate_calc_field_dict()\n",
    "    for field in [\"model-only_conf\", \"model-only_unconf\"]:\n",
    "        exp_dict[field] = \"-\"+points\n",
    "    for field in [\"iMap-only_conf\", \"iMap-only_unconf\"]:\n",
    "        exp_dict[field] = \"0\"\n",
    "    exp_dict[\"Overlap_conf\"] = points+\"/(\"+iMap_cnfrm+extra+\")\" # Effectively, \"extra\" adds imap_nd if thresholdless and doesn't for thresholded\n",
    "    exp_dict[\"Overlap_unconf\"] = points+\"/(\"+iMap_cnfrm+\" + \"+iMap_uncnfrm+extra+\")\" # Do the same as above line including unconfirmed in the calc\n",
    "    if type == \"THRESHOLDED\":\n",
    "        exp_dict[\"iMap-only_nd\"] = \"0\"\n",
    "        exp_dict[\"model-only_nd\"] = \"-(\"+model_possible+\" - \"+model_positives+\")\"\n",
    "        exp_dict[\"Overlap_nd\"] = \"(\"+model_possible+\" - \"+model_positives+\")/\"+iMap_nd\n",
    "    \n",
    "    return(exp_dict)\n",
    "\n",
    "def add_calc_fields(dataset, calc_field_dict):\n",
    "    # Get a unique list of fields by first converting to a set that only contains the unique values\n",
    "    unique_comp_field_names = list(set(calc_field_dict.values()))\n",
    "    # Get list of existing fields\n",
    "    field_objs = arcpy.ListFields(dataset)\n",
    "    field_names = list()\n",
    "    for field in field_objs:\n",
    "        field_names.append(field.name)\n",
    "    for comp_field in unique_comp_field_names:\n",
    "        if comp_field not in field_names:\n",
    "            arcpy.management.AddField(dataset, comp_field, \"FLOAT\", field_alias=comp_field)\n",
    "\n",
    "# Delete temporary files\n",
    "# This way is necessary to delete the feature itself and not just its contents\n",
    "def delete_tmp_features(feature_list):\n",
    "    import os\n",
    "    cws = arcpy.env.workspace\n",
    "    for f in feature_list:\n",
    "      f_path = os.path.join(cws, f)\n",
    "      if arcpy.Exists(f_path):\n",
    "        arcpy.Delete_management(f_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Code to create a fishnet for the state if you do not already have one\n",
    "# # New york state boundary coordinates in UTM Zone 18N projection \n",
    "# # (Coordinates are expressed in the order of x-min, y-min, x-max, y-max)\n",
    "# aoi = ['4,481,032.099500 105,606.381800 4,985,489.904000 770,761.900100'] \n",
    "# cellsize = '1' # The width and height argument for the fishnet function\n",
    "# fishnet_output_name = rag_empty\n",
    "# # Create fishnet \n",
    "# arcpy.management.CreateFishnet(fishnet_output_name, '4,985,489.904000 105,606.381800', '4,481,032.099500 105,606.381800', cellsize, cellsize, '0', '0', {corner_coord}, 'NO_LABELS', aoi, 'POLYGON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Thresholdless Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wp\n",
      "toh\n",
      "pl\n",
      "Calculating total iMap features joined\n",
      "Summing: ('!imap_point_cnfrm!', '!imap_line_cnfrm!', '!imap_poly_cnfrm!')\n",
      "Summing: ['!imap_point_uncnfrm!', '!imap_line_uncnfrm!', '!imap_poly_uncnfrm!']\n",
      "Calculating comparison values\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# For thresholdless reporting analysis\n",
    "# Create empty lists to ultimately populate a dataframe\n",
    "out_features = []\n",
    "join_features = []\n",
    "field_names = []\n",
    "tmp_ps_joins = []\n",
    "\n",
    "# Assign names for overall model prediction join\n",
    "# These join counts are used for species with no panorama date restirctions on interpretation\n",
    "out_features.append(\"tmpRAG_model\")\n",
    "join_features.append(model_pred)\n",
    "field_names.append(\"model_points\")\n",
    "# Assign names for joins of species with panorama date restrictions on interpretation\n",
    "for species in date_constrained_species:\n",
    "    print(species)\n",
    "    ps_join_feature = \"tmp_model_pred_\"+species\n",
    "    tmp_ps_joins.append(ps_join_feature)\n",
    "    if species == \"wp\":\n",
    "        whereClause = (\"date LIKE '%-05' Or date LIKE '%-06' Or date LIKE '%-07'\"\n",
    "                    )\n",
    "    if species == \"toh\":\n",
    "        whereClause = (\"date LIKE '%-07' Or date LIKE '%-08' Or date LIKE '%-09' Or date LIKE '%-10'\"\n",
    "                    )\n",
    "    if species == \"pl\":\n",
    "        whereClause = (\"date LIKE '%-07' Or date LIKE '%-08' Or date LIKE '%-09' Or date LIKE '%-10'\"\n",
    "                    ) \n",
    "    print(whereClause)\n",
    "    ps_sel = arcpy.management.SelectLayerByAttribute(model_pred, \"NEW_SELECTION\", whereClause)\n",
    "    arcpy.management.CopyFeatures(ps_sel, ps_join_feature)\n",
    "    arcpy.management.SelectLayerByAttribute(model_pred, \"CLEAR_SELECTION\")\n",
    "\n",
    "    out_features.append(\"tmpRAG_model_\"+species)\n",
    "    join_features.append(ps_join_feature)\n",
    "    del ps_join_feature\n",
    "    field_names.append(\"model_\"+species+\"_possible\")\n",
    "\n",
    "# Assign field names for iMap joins and to delete later\n",
    "geo_names = {\"point\": \"POINT\",\n",
    "             \"line\": \"LINE\",\n",
    "             \"poly\": \"POLYGON\"\n",
    "}\n",
    "geometries = geo_names.keys()\n",
    "type_names = {\"cnfrm\": \"\",\n",
    "              \"uncnfrm\": \"_UNCONFIRMED\",\n",
    "              \"nd\": \"\"\n",
    "}\n",
    "types = type_names.keys()\n",
    "tmpCnfrm = list()\n",
    "tmpUncnfrm = list()\n",
    "for record_type in types:\n",
    "    for geometry in geometries:\n",
    "        if record_type == \"nd\":\n",
    "            if geometry == \"poly\":\n",
    "                imap_prefix = \"NOT_DETECTED\"\n",
    "                imap_suffix = \"nd\"\n",
    "            else:\n",
    "                continue\n",
    "        else:\n",
    "            imap_prefix = \"PRESENCE\"\n",
    "            imap_suffix = geometry+\"_\"+record_type\n",
    "        out_features.append(\"tmpRAG_\"+imap_suffix)\n",
    "        join_features.append(imap_prefix+\"_\"+geo_names[geometry]+type_names[record_type])\n",
    "        fname = \"imap_\"+imap_suffix\n",
    "        # Add to list to delete\n",
    "        field_names.append(fname)\n",
    "        # Add to lists for summing calculations\n",
    "        if record_type == \"cnfrm\":\n",
    "            tmpCnfrm.append(\"!\"+fname+\"!\")\n",
    "        elif record_type == \"uncnfrm\":\n",
    "            tmpUncnfrm.append(\"!\"+fname+\"!\")\n",
    "        del fname\n",
    "# Combine/create lists to put in the dataframe organizing spatial join inputs/outputs\n",
    "target_features = [rag_empty,]\n",
    "for out_feature in out_features:\n",
    "    target_features.append(out_feature)\n",
    "\n",
    "zipped = list(zip(target_features, join_features, out_features, field_names))\n",
    "import pandas as pd\n",
    "ps_name_df = pd.DataFrame(zipped, columns=['Target_Feature', 'Join_Feature', 'Out_Feature', 'Field_Name'])\n",
    "del target_features, join_features, out_features, zipped\n",
    "# Re-name the last output feature name in the dataframe\n",
    "RAG_tl = \"reporting_analysis_grid_thresholdless\"\n",
    "ps_name_df.at[len(ps_name_df)-1, \"Out_Feature\"]=RAG_tl\n",
    "ps_name_df\n",
    "\n",
    "for i in range(0,len(ps_name_df)):\n",
    "    target_feature = ps_name_df.at[i, \"Target_Feature\"]\n",
    "    join_feature = ps_name_df.at[i, \"Join_Feature\"]\n",
    "    out_feature = ps_name_df.at[i, \"Out_Feature\"]\n",
    "    field_name = ps_name_df.at[i, \"Field_Name\"]\n",
    "    fm = create_SJ_FieldMappings(target_feature, join_feature) # Create the field mappings for the join\n",
    "    arcpy.analysis.SpatialJoin(target_feature, join_feature, out_feature, \"JOIN_ONE_TO_ONE\", \"KEEP_ALL\", fm) # Count the features within each grid cell\n",
    "    arcpy.management.AlterField(out_feature, \"JOIN_COUNT\", field_name, field_name) # Rename join_count field\n",
    "    arcpy.management.DeleteField(out_feature, \"TARGET_FID\") # Delete unnecessary field\n",
    "    del target_feature, join_feature, out_feature, field_name, fm\n",
    "\n",
    "# Calculate the total number of iMap features joined\n",
    "print(\"Calculating total iMap features joined\")\n",
    "\n",
    "cName = \"iMap_cnfrm\"\n",
    "uName = \"iMap_uncnfrm\"\n",
    "arcpy.management.AddFields(RAG_tl, [\n",
    "    [cName, 'SHORT'],\n",
    "    [uName, 'SHORT']\n",
    "])\n",
    "\n",
    "tmpCnfrm = tuple(tmpCnfrm)\n",
    "print(\"Summing:\",tmpCnfrm)\n",
    "arcpy.management.CalculateField(RAG_tl, cName, tmpCnfrm[0]+\"+\"+tmpCnfrm[1]+\"+\"+tmpCnfrm[2])\n",
    "print(\"Summing:\",tmpUncnfrm)\n",
    "tmpUncnfrm = tuple(tmpUncnfrm)\n",
    "arcpy.management.CalculateField(RAG_tl, uName, tmpUncnfrm[0]+\"+\"+tmpUncnfrm[1]+\"+\"+tmpUncnfrm[2])\n",
    "\n",
    "print(\"Calculating comparison values\")\n",
    "type = \"NOT_THRESHOLDED\"\n",
    "fieldDict = generate_calc_field_dict(type)\n",
    "expDict = generate_calc_expressions(type)\n",
    "wCs = generate_where_clauses(type)\n",
    "add_calc_fields(RAG_tl, fieldDict)\n",
    "\n",
    "for key in wCs: # Loop to calculate the reporting analysis values\n",
    "    sel = arcpy.management.SelectLayerByAttribute(RAG_tl, \"NEW_SELECTION\", wCs[key]) # Make the selection\n",
    "    arcpy.management.CalculateField(sel, fieldDict[key], expDict[key]) # Calculate values in field based on expression\n",
    "    arcpy.management.SelectLayerByAttribute(RAG_tl, \"CLEAR_SELECTION\")\n",
    "    del sel\n",
    "\n",
    "# Remove fields we want to keep from the list of fields to delete\n",
    "field_names.remove(\"model_points\")\n",
    "field_names.remove(\"imap_nd\")\n",
    "for species in date_constrained_species:\n",
    "    field_names.remove(\"model_\"+species+\"_possible\")\n",
    "# Delete the now unnecessary per-geometry fields\n",
    "for field in field_names:\n",
    "    arcpy.management.DeleteField(RAG_tl, field)\n",
    "    \n",
    "del type, fieldDict, expDict, wCs, field_names, tmpCnfrm, tmpUncnfrm\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of all but the last output feature to delete\n",
    "tmp_out_features = ps_name_df[\"Out_Feature\"][:-1].to_list()\n",
    "# Delete temporary files\n",
    "delete_tmp_features(tmp_out_features)\n",
    "delete_tmp_features(tmp_ps_joins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Species-Based Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers to process: 40\n",
      "['SVI_Project_presences_phrag_precision', 'SVI_Project_presences_knot_precision', 'SVI_Project_presences_wp_precision', 'SVI_Project_presences_toh_precision', 'SVI_Project_presences_pl_precision', 'iMap_nd_phrag', 'iMap_point_cnfrm_phrag', 'iMap_line_cnfrm_phrag', 'iMap_polygon_cnfrm_phrag', 'iMap_point_uncnfrm_phrag', 'iMap_line_uncnfrm_phrag', 'iMap_polygon_uncnfrm_phrag', 'iMap_nd_knot', 'iMap_point_cnfrm_knot', 'iMap_line_cnfrm_knot', 'iMap_polygon_cnfrm_knot', 'iMap_point_uncnfrm_knot', 'iMap_line_uncnfrm_knot', 'iMap_polygon_uncnfrm_knot', 'iMap_nd_wp', 'iMap_point_cnfrm_wp', 'iMap_line_cnfrm_wp', 'iMap_polygon_cnfrm_wp', 'iMap_point_uncnfrm_wp', 'iMap_line_uncnfrm_wp', 'iMap_polygon_uncnfrm_wp', 'iMap_nd_toh', 'iMap_point_cnfrm_toh', 'iMap_line_cnfrm_toh', 'iMap_polygon_cnfrm_toh', 'iMap_point_uncnfrm_toh', 'iMap_line_uncnfrm_toh', 'iMap_polygon_uncnfrm_toh', 'iMap_nd_pl', 'iMap_point_cnfrm_pl', 'iMap_line_cnfrm_pl', 'iMap_polygon_cnfrm_pl', 'iMap_point_uncnfrm_pl', 'iMap_line_uncnfrm_pl', 'iMap_polygon_uncnfrm_pl']\n"
     ]
    }
   ],
   "source": [
    "# Separate out iMap records by species and geometry\n",
    "\n",
    "# Add model data layer names to processing list\n",
    "# Create list of n + n*3 files to process, where n is the number of species\n",
    "ps_records = [] # empty list to append per-species records onto\n",
    "# Add names to list\n",
    "for n in range(0,len(species_shortnames)):\n",
    "    # Add n items for model data \n",
    "    ps_records.append('SVI_Project_presences_'+species_shortnames[n]+\"_\"+threshold)\n",
    "\n",
    "    \n",
    "# Define list of geometries in the iMap data\n",
    "imap_geometries = [\"POINT\", \"LINE\", \"POLYGON\"]\n",
    "# Define imap records types\n",
    "imap_record_types = {\n",
    "    \"cnfrm\": \"_Conf\", # The \"suffix\" for confirmed records is blank\n",
    "    \"uncnfrm\": \"_Unconf\"\n",
    "}\n",
    "# Add n*2*3 + n items for iMap data (accounts for 2 record and 3 geometry types, \n",
    "# plus not-detected records) \n",
    "for n in range(0,len(species_shortnames)):\n",
    "    # Set up per-species query for selecting by attribute\n",
    "    if species_shortnames[n] is \"knot\":\n",
    "        # Set initial SQL query\n",
    "        idClause = \"jurisdiction_species_id = \"+str(jurisdiction_ids[\"knot\"][0])\n",
    "        # Add more conditions to query\n",
    "        for ID in jurisdiction_ids[\"knot\"][1:]:\n",
    "            idClause = idClause + \" Or jurisdiction_species_id = \" + str(ID)\n",
    "    else:\n",
    "        idClause = \"jurisdiction_species_id = \"+str(jurisdiction_ids[species_shortnames[n]]) \n",
    "    \n",
    "    # Copy a per-species subset of not detected polygons\n",
    "    sel = arcpy.management.SelectLayerByAttribute(\"NOT_DETECTED_POLYGON\", \"NEW_SELECTION\", idClause)\n",
    "    imap_nd = \"iMap_nd_\"+species_shortnames[n]\n",
    "    arcpy.management.CopyFeatures(sel, imap_nd)\n",
    "    ps_records.append(imap_nd)\n",
    "    # Remove variables and selections to save memory\n",
    "    del sel, imap_nd\n",
    "    arcpy.management.SelectLayerByAttribute(\"NOT_DETECTED_POLYGON\", \"CLEAR_SELECTION\")\n",
    "    \n",
    "    # Copy a per-species subset for each record and geometry type\n",
    "    for rt in range(0,len(imap_record_types)):\n",
    "        if rt == 0: # Confirmed\n",
    "            rt_suffix = \"\"\n",
    "        elif rt == 1: # Unconfirmed\n",
    "            rt_suffix = \"_UNCONFIRMED\"\n",
    "        for g in range(0,len(imap_geometries)):\n",
    "            sel = arcpy.management.SelectLayerByAttribute(\"PRESENCE_\"+imap_geometries[g]+rt_suffix, \"NEW_SELECTION\", idClause)\n",
    "            imap_subset = \"iMap_\"+imap_geometries[g].lower()+\"_\"+list(imap_record_types.keys())[rt]+\"_\"+species_shortnames[n]\n",
    "            arcpy.management.CopyFeatures(sel, imap_subset)\n",
    "            ps_records.append(imap_subset)\n",
    "            # Remove variables and selections to save memory\n",
    "            del sel, imap_subset\n",
    "            arcpy.management.SelectLayerByAttribute(\"PRESENCE_\"+imap_geometries[g], \"CLEAR_SELECTION\")\n",
    "        \n",
    "print(\"Number of layers to process: \"+str(len(ps_records)))\n",
    "print(ps_records)\n",
    "\n",
    "del imap_geometries, imap_record_types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create analysis-ready version (1 layer with fields for all species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_phrag\n",
      "model_knot\n",
      "model_wp\n",
      "model_toh\n",
      "model_pl\n",
      "iMap_nd_phrag\n",
      "iMap_point_cnfrm_phrag\n",
      "iMap_line_cnfrm_phrag\n",
      "iMap_polygon_cnfrm_phrag\n",
      "iMap_point_uncnfrm_phrag\n",
      "iMap_line_uncnfrm_phrag\n",
      "iMap_polygon_uncnfrm_phrag\n",
      "iMap_nd_knot\n",
      "iMap_point_cnfrm_knot\n",
      "iMap_line_cnfrm_knot\n",
      "iMap_polygon_cnfrm_knot\n",
      "iMap_point_uncnfrm_knot\n",
      "iMap_line_uncnfrm_knot\n",
      "iMap_polygon_uncnfrm_knot\n",
      "iMap_nd_wp\n",
      "iMap_point_cnfrm_wp\n",
      "iMap_line_cnfrm_wp\n",
      "iMap_polygon_cnfrm_wp\n",
      "iMap_point_uncnfrm_wp\n",
      "iMap_line_uncnfrm_wp\n",
      "iMap_polygon_uncnfrm_wp\n",
      "iMap_nd_toh\n",
      "iMap_point_cnfrm_toh\n",
      "iMap_line_cnfrm_toh\n",
      "iMap_polygon_cnfrm_toh\n",
      "iMap_point_uncnfrm_toh\n",
      "iMap_line_uncnfrm_toh\n",
      "iMap_polygon_uncnfrm_toh\n",
      "iMap_nd_pl\n",
      "iMap_point_cnfrm_pl\n",
      "iMap_line_cnfrm_pl\n",
      "iMap_polygon_cnfrm_pl\n",
      "iMap_point_uncnfrm_pl\n",
      "iMap_line_uncnfrm_pl\n",
      "iMap_polygon_uncnfrm_pl\n",
      "All done\n"
     ]
    }
   ],
   "source": [
    "# Spatial join repeatedly\n",
    "input_grid = RAG_tl\n",
    "tmpFeatures = list()\n",
    "# Used for tracking iterations which enables field calculations to be performed after \n",
    "# confirmed and unconfirmed iMap records of all geometries are spatially joined\n",
    "counter = 1\n",
    "# Effectively, for iMap and model data, each species, and geometry/record type (if iMap data):\n",
    "for i, r in enumerate(ps_records):\n",
    "    # Define field naming convention\n",
    "    if \"SVI\" in r:\n",
    "        # Slice to only retain the species and create new field name\n",
    "        species = r[22:-10]\n",
    "        field_name = \"model_\"+species\n",
    "    else:\n",
    "        field_name = r\n",
    "    print(field_name)\n",
    "    fm = create_SJ_FieldMappings(input_grid, r) # Create the field mappings for this join\n",
    "\n",
    "    # Perform the spatial join & clean the table\n",
    "    out_grid = \"tmp_grid_\"+str(i)\n",
    "    tmpFeatures.append(out_grid) # add to list for deleting later\n",
    "    arcpy.analysis.SpatialJoin(input_grid,r,out_grid,\"JOIN_ONE_TO_ONE\",\"KEEP_ALL\",fm)\n",
    "    del fm\n",
    "    # Rename Join_Count field\n",
    "    arcpy.management.AlterField(out_grid, \"Join_Count\", field_name, field_name)\n",
    "    # Delete TARGET_FID field\n",
    "    arcpy.management.DeleteField(out_grid, \"TARGET_FID\")\n",
    "    \n",
    "    # Sum records only after confirmed or unconfirmed iMap records of all geometries are spatially joined\n",
    "    if i >= len(species_shortnames): # Check if our iteration index is past processing model data\n",
    "        # Determine the oscillation\n",
    "        if \"nd\" in r:\n",
    "            x = 4\n",
    "        elif \"point_uncnfrm\" in r:\n",
    "            x = 3\n",
    "        # Effectively oscillate between running every 4th and 3rd entry, respectively \n",
    "        if (counter == x): # Check if the counter is at the oscillating xth entry we're targeting\n",
    "            counter = 0 # Reset the count\n",
    "\n",
    "            sum_fields = ps_records[i-2:i+1] # Select three fields of interest to sum\n",
    "            sum_name = \"iMap_\"+r[13:] # Create desired field name\n",
    "            express = \"!\"+sum_fields[0]+\"!+!\"+sum_fields[1]+\"!+!\"+sum_fields[2]+\"!\" # Create expression for calculating sum \n",
    "            arcpy.management.AddField(out_grid, sum_name, \"SHORT\") # Create the field\n",
    "            arcpy.management.CalculateField(out_grid,sum_name,express) # Sum the fields\n",
    "            for field in sum_fields: # Loop through the fields used when summing\n",
    "                arcpy.management.DeleteField(out_grid, field) # Delete the field from the feature since it's no longer necessary\n",
    "        counter += 1 # Add 1 to the count\n",
    "    input_grid = \"tmp_grid_\"+str(i) # Make the next run's target grid the output of this iteration's spatial join\n",
    "    if i == len(ps_records)-1: # Check if the last iteration\n",
    "        RAG_final = \"SVI_Proj_reporting_analysis_grid_\"+threshold\n",
    "        arcpy.management.CopyFeatures(out_grid, RAG_final) # Copy to a new feature\n",
    "        del counter, input_grid, out_grid\n",
    "\n",
    "# Delete unmerged presence points\n",
    "delete_tmp_features(tmpFeatures)\n",
    "del tmpFeatures\n",
    "\n",
    "print(\"All done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phrag\n",
      "***Checking key names\n",
      "***Adding comparison fields\n",
      "***Calculating comparison values\n",
      "knot\n",
      "***Checking key names\n",
      "***Adding comparison fields\n",
      "***Calculating comparison values\n",
      "wp\n",
      "***Checking key names\n",
      "***Adding comparison fields\n",
      "***Calculating comparison values\n",
      "toh\n",
      "***Checking key names\n",
      "***Adding comparison fields\n",
      "***Calculating comparison values\n",
      "pl\n",
      "***Checking key names\n",
      "***Adding comparison fields\n",
      "***Calculating comparison values\n",
      "Analysis version of the reporting gap analysis complete\n"
     ]
    }
   ],
   "source": [
    "# Calculate per-species ND ratios, confirmed ratios, unconfirmed ratios, and rato percentiles\n",
    "\n",
    "for species in species_shortnames:\n",
    "    print(species)\n",
    "    print(\"***Checking key names\")\n",
    "    type = \"THRESHOLDED\"\n",
    "    fieldDict = generate_calc_field_dict(type, species)\n",
    "    expDict = generate_calc_expressions(type, species)\n",
    "    wCs = generate_where_clauses(type, species)\n",
    "    a = len(fieldDict)\n",
    "    b = len(expDict)\n",
    "    c = len(wCs)\n",
    "    if a == b and b == c:\n",
    "        pass\n",
    "    else:\n",
    "        print(\"******Error in key names of one or more of fieldDict, expDict, and wCs\")\n",
    "        quit()\n",
    "    print(\"***Adding comparison fields\")\n",
    "    add_calc_fields(RAG_final, fieldDict)\n",
    "    print(\"***Calculating comparison values\")\n",
    "    for key in wCs: # Loop to calculate the reporting analysis values\n",
    "        sel = arcpy.management.SelectLayerByAttribute(RAG_final, \"NEW_SELECTION\", wCs[key]) # Make the selection\n",
    "        arcpy.management.CalculateField(sel, fieldDict[key], expDict[key]) # Calculate values in field based on expression\n",
    "        arcpy.management.SelectLayerByAttribute(RAG_final, \"CLEAR_SELECTION\")\n",
    "        del sel\n",
    "    del type, fieldDict, expDict, wCs\n",
    "\n",
    "    # Calculate percentile field that describes the percentile of model-only record magnitude and imap-model overlap ratio ----------\n",
    "    import scipy\n",
    "    from scipy.stats import percentileofscore # For calculating the percentile of each value\n",
    "    filters = [\" < 0\", \" > 0\"]\n",
    "    comp_types = [\"Cc_\", \"CUc_\", \"NDc_\"]\n",
    "    for comp_type in comp_types: # For each comparison type (Confirmed, Unconfirmed, Not detected)\n",
    "        ratio_field = comp_type+species\n",
    "        pct_field = \"pct_\"+ratio_field\n",
    "        arcpy.management.AddField(RAG_final, pct_field, \"FLOAT\")\n",
    "        for filter in filters: # For (effectively) both the overlap and model-only sets\n",
    "            rga_values = [abs(row.getValue(ratio_field)) for row in arcpy.SearchCursor(RAG_final, ratio_field+filter)] # Return a list of all reporting gap analysis magnitudes (only positives or negatives, no nulls)\n",
    "            cursor = arcpy.UpdateCursor(RAG_final, ratio_field+filter)\n",
    "            if filter is \" < 0\":\n",
    "                x = -1 # Make model-only percentiles negative\n",
    "            else:\n",
    "                x = 1 # Keep overlap percentiles positive\n",
    "            for i, row in enumerate(cursor): # For each row in the filtered dataset\n",
    "                pct_v = x*scipy.stats.percentileofscore(rga_values, abs(row.getValue(ratio_field)), kind='mean') # Calculate the percentile of the reporting gap analysis value\n",
    "        #         if i < 20: # View the first 20 ratio and percentile values\n",
    "        #             print(\"r \",abs(row.getValue(ratio_field)))\n",
    "        #             print(\"p \",pct_v)\n",
    "                row.setValue(pct_field, pct_v) # Assign the percentile of that reporting gap analysis value\n",
    "                cursor.updateRow(row) # As far as I understand, this locks in that edit\n",
    "                del pct_v\n",
    "            del rga_values, cursor\n",
    "        # Add zeroes to cells where there's only iMap data\n",
    "        cursor = arcpy.UpdateCursor(RAG_final, ratio_field+\" = 0\")\n",
    "        for row in cursor:\n",
    "            row.setValue(pct_field, 0)\n",
    "            cursor.updateRow(row)\n",
    "        del cursor\n",
    "del filters\n",
    "print(\"Analysis version of the reporting gap analysis complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the viewing-ready version (1 layer with combined comp and pct fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section pseudocode\n",
    "# For each species:\n",
    "    # Select records with non-null values for that species\n",
    "    # Copy to new feature\n",
    "    # Collapse per-species ratio and percentile fields into two new ones \n",
    "    # Delete per-species ratio and percentile fields\n",
    "    # Add & calculate common name, jurisdiction id, and op criteria fields\n",
    "# Merge layers into one for upload into AGOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Viewing layer of the reporting gap analysis complete\n"
     ]
    }
   ],
   "source": [
    "merge_sets = list() # Updated to contain the per-species layers to merge\n",
    "\n",
    "for species in species_shortnames: # For each species\n",
    "    whereClause = \"\"\n",
    "    # Create where clause used to select cells where there are records\n",
    "    for i, comp_type in enumerate(comp_types):\n",
    "        ratio_field = comp_type+species\n",
    "        \n",
    "        if i < 1:\n",
    "            whereClause = ratio_field + \" IS NOT NULL\"\n",
    "        else: \n",
    "            whereClause = whereClause + \" or \" + ratio_field + \" IS NOT NULL\"\n",
    "        del ratio_field\n",
    "\n",
    "    sel = arcpy.management.SelectLayerByAttribute(RAG_final, \"NEW_SELECTION\", whereClause) # Select cells where there are records\n",
    "    \n",
    "    ps_viewing_layer = \"tmp_ps_view_\"+species\n",
    "    arcpy.management.CopyFeatures(sel, ps_viewing_layer) # Create a copy of records for just this species\n",
    "    merge_sets.append(ps_viewing_layer) # Add to list for merging later\n",
    "\n",
    "    \n",
    "    for comp_type in comp_types:\n",
    "        ratio_field = comp_type+species\n",
    "        pct_field = \"pct_\"+ratio_field\n",
    "        \n",
    "        # Collapse per-species field values into two fields\n",
    "        arcpy.management.CalculateField(ps_viewing_layer, comp_type+\"ps\", \"!\"+ratio_field+\"!\")\n",
    "        arcpy.management.CalculateField(ps_viewing_layer, comp_type+\"ps_pct\", \"!\"+pct_field+\"!\")\n",
    "\n",
    "        arcpy.management.DeleteField(ps_viewing_layer, [ratio_field, pct_field]) # Delete per-species fields\n",
    "    \n",
    "    # Add some attribute fields to enable filtering in the ArcGIS Online dashboard\n",
    "    arcpy.management.CalculateField(ps_viewing_layer, \"Common_Nam\", species_fullnames[species])\n",
    "    if species is \"knot\":\n",
    "        jsid = 1479 # Knotweed unspecified\n",
    "    else:\n",
    "        jsid = jurisdiction_ids[species]\n",
    "    arcpy.management.CalculateField(ps_viewing_layer, \"jurisdiction_species_id\", jsid)\n",
    "    arcpy.management.CalculateField(ps_viewing_layer, \"op_criteria\", \"'\"+threshold+\"'\")\n",
    "\n",
    "arcpy.management.Merge(merge_sets, \"SVI_Proj_RAG_1km_Viewing\")\n",
    "\n",
    "print(\"Viewing layer of the reporting gap analysis complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete temporary features and vars\n",
    "\n",
    "# Make list of features to delete\n",
    "tmpFeatures = list()\n",
    "for species in species_shortnames:\n",
    "    tmpFeatures.append(\"tmp_ps_view_\"+species) # Add per-species layers\n",
    "    tmpFeatures.append(\"iMap_nd_\"+species) # Add iMap not-detected\n",
    "    for rt in ['cnfrm', 'uncnfrm']:\n",
    "        for geometry in ['point', 'line', 'polygon']:\n",
    "            tmpFeatures.append(\"iMap_\"+geometry+\"_\"+rt+\"_\"+species) # Add iMap polygon\n",
    "# Delete unmerged presence points\n",
    "delete_tmp_features(tmpFeatures)\n",
    "# Delete user-defined variables\n",
    "for obj in dir():\n",
    "    if not obj.startswith(\"__\"): # If not a system var\n",
    "        del globals()[obj] # Delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3"
  },
  "vscode": {
   "interpreter": {
    "hash": "8f58821842ebfdc7cbfe1f42095cc50c88f3bb71d7cdf4c3472b8320885a5152"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
