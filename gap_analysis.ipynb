{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nReporting Gap Analysis\\nAuthor: Liam Megraw, RIT Envirionmental Science Technician\\nDate last edited: 3/9/2023\\nESRI ArcGIS Pro Version 2.7\\n\\nDescription:\\nThis code processes uses results from the RIT-developed computer \\nvision model and iMapInvasives records to identify gaps in reporting\\non a per-species basis. The first part compares all iMap and model \\nrecords for the species of interest at the same time, while the \\nsecond part compares them on a per-species basis.\\n\\nInputs:\\n> Single point dataset of model prediction points with n species each\\n  having their own confidence score column\\n> 7 iMapInvasives datasets for n species\\n    > Presence points (confirmed)\\n    > Presence lines (confirmed)\\n    > Presence polygons (confirmed)\\n    > Presence points (unconfirmed)\\n    > Presence lines (unconfirmed)\\n    > Presence polygons (unconfirmed)\\n    > Not detected polygons\\n> n point datasets of model presence predictions at a threshold (For per-species approach)\\n\\nOutputs:\\nThe final outputs are two polygon layers at a 1 km resolution with \\noverall and per-species attributes detailing the type of records \\nwithin a cell (model only, iMap only, or both), and if there is \\noverlap, a comparison value between the two types of records.\\n\\nHow to Use:\\nThese layers can be hosted on the ArcGIS Online Public and Manager Dashboards.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Reporting Gap Analysis\n",
    "Author: Liam Megraw, RIT Envirionmental Science Technician\n",
    "Date last edited: 3/14/2023\n",
    "ESRI ArcGIS Pro Version 2.7\n",
    "\n",
    "Description:\n",
    "This code processes uses results from the RIT-developed computer \n",
    "vision model and iMapInvasives records to identify gaps in reporting\n",
    "on a per-species basis. The first part compares all iMap and model \n",
    "records for the species of interest at the same time, while the \n",
    "second part compares them on a per-species basis.\n",
    "\n",
    "Inputs:\n",
    "> Single point dataset of model prediction points with n species each\n",
    "  having their own confidence score column\n",
    "> 7 iMapInvasives datasets for n species\n",
    "    > Presence points (confirmed)\n",
    "    > Presence lines (confirmed)\n",
    "    > Presence polygons (confirmed)\n",
    "    > Presence points (unconfirmed)\n",
    "    > Presence lines (unconfirmed)\n",
    "    > Presence polygons (unconfirmed)\n",
    "    > Not detected polygons\n",
    "> n point datasets of model presence predictions at a threshold (For per-species approach)\n",
    "\n",
    "Outputs:\n",
    "The final outputs are two polygon layers at a 1 km resolution with \n",
    "overall and per-species attributes detailing the type of records \n",
    "within a cell (model only, iMap only, or both), and if there is \n",
    "overlap, a comparison value between the two types of records.\n",
    "\n",
    "How to Use:\n",
    "These layers can be hosted on the ArcGIS Online Public and Manager Dashboards.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPseudocode Overview\\n\\nAssign workspace\\n(Optionally) create state-wide fishnets at 1 km resolution\\nCreate lists of input files\\n    iMap: point, line, polygon\\n    model: point\\nDefine function to creat field mappings for spatial joins\\n\\nThresholdless approach\\n    Effectively, for both model data and iMap data, and each imap geometry type:\\n            Spatial join records to fishnet\\n            Add & calculate fields\\n                Total join count for that species\\n                Overlap type if statement:\\n                    Cells where model data join count is above zero and iMap join count above zero: both (i.e., overlap)\\n                    Cells where model data join count is above zero and iMap join count is zero: (i.e, model only)\\n                    Cells where model data join count is zero and iMap join count is above zero (i.e., iMap only)\\n                Calculate comparison between model and iMap\\nThresholded (per-species) approach\\n    For each species:\\n        Export iMap records to layers split by species, record type, and geometry\\n        Spatially join records to fishnet\\n        \\nExport results\\n\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Pseudocode Overview\n",
    "\n",
    "Assign workspace\n",
    "(Optionally) create state-wide fishnets at 1 km resolution\n",
    "Create lists of input files\n",
    "    iMap: point, line, polygon\n",
    "    model: point\n",
    "Define function to creat field mappings for spatial joins\n",
    "\n",
    "Thresholdless approach\n",
    "    Effectively, for both model data and iMap data, and each imap geometry type:\n",
    "            Spatial join records to fishnet\n",
    "            Add & calculate fields\n",
    "                Total join count for that species\n",
    "                Overlap type if statement:\n",
    "                    Cells where model data join count is above zero and iMap join count above zero: both (i.e., overlap)\n",
    "                    Cells where model data join count is above zero and iMap join count is zero: (i.e, model only)\n",
    "                    Cells where model data join count is zero and iMap join count is above zero (i.e., iMap only)\n",
    "                Calculate comparison between model and iMap\n",
    "Thresholded (per-species) approach\n",
    "    For each species:\n",
    "        Export iMap records to layers split by species, record type, and geometry\n",
    "        Spatially join records to fishnet\n",
    "        \n",
    "Export results\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----- Get and set workspace to gdb -----\n",
    "import arcpy\n",
    "from arcpy import env\n",
    "arcpy.env.workspace = r'C:\\Users\\ltmsbi\\Documents\\ArcGIS\\Projects\\Final_Deployment\\Final_Deployment.gdb'\n",
    "\n",
    "arcpy.env.OverwriteOutput = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iMap datasets:\n",
      "['PRESENCE_POINT', 'PRESENCE_POINT_UNCONFIRMED', 'PRESENCE_LINE', 'PRESENCE_LINE_UNCONFIRMED', 'PRESENCE_POLYGON', 'PRESENCE_POLYGON_UNCONFIRMED', 'NOT_DETECTED_POLYGON']\n"
     ]
    }
   ],
   "source": [
    "# Necessary input files\n",
    "model_pred = [\"pred_finalDeployment_all\",] # each species must have their own column\n",
    "\n",
    "def create_SJ_FieldMappings(targetLayer, joinLayer): # Return field mappings for spatial joins when called \n",
    "    \n",
    "    # List starting fields for spatial joins that'll be updated with each successive join\n",
    "    keepFields = list()\n",
    "    omitFields = [\"OBJECTID\", \"Shape\", \"Shape_Area\", \"Shape_Length\"]\n",
    "\n",
    "    for field in arcpy.ListFields(targetLayer):\n",
    "        if field.name not in omitFields:\n",
    "            keepFields.append(field.name)\n",
    "    \n",
    "    fieldMappings = arcpy.FieldMappings() # field mapping variable; this will store all field mappings\n",
    "\n",
    "    # Create list of field names to keep in the output file\n",
    "    targetTable = []\n",
    "    for i in arcpy.ListFields(targetLayer):\n",
    "        if i.name in (keepFields):\n",
    "            targetTable.append(i.name)\n",
    "\n",
    "    # List of input feature classes for the spatial join\n",
    "    f = [targetLayer, joinLayer]\n",
    "\n",
    "    for k in targetTable: # loop through main table\n",
    "        #print(\"Field: \",k)\n",
    "        fieldMap = arcpy.FieldMap() # create an empty field map variable\n",
    "        fieldMap.addInputField(targetLayer,k) # insert the target layer as the first input into the field map\n",
    "        for feature in f: # loop through feature classes\n",
    "            for field in arcpy.ListFields(feature): # loop through field of each feature class\n",
    "                if k in field.name: # check if any field matches with our target field then append it as an input field\n",
    "                    fieldMap.addInputField(feature,field.name) \n",
    "        fieldMappings.addFieldMap(fieldMap) # add the current field map to the main field map variable\n",
    "    return(fieldMappings)\n",
    "\n",
    "def generateWhereClauses(type): # Return a dictionary of where clauses to select records for calculations when called \n",
    "    if type == \"THRESHOLDED\":\n",
    "        l_suffix = \"_\"+species\n",
    "        points = \"model\"+l_suffix\n",
    "        extras = [\"\",\")\"]\n",
    "    elif type == \"NOT_THRESHOLDED\":\n",
    "        l_suffix = \"\"\n",
    "        points = \"model_points\"\n",
    "        extras = [\" And iMap_nd = 0\", \" Or iMap_nd > 0)\"]\n",
    "\n",
    "    iMap_cnfrm = \"imap_cnfrm\"+l_suffix\n",
    "    iMap_uncnfrm = \"imap_uncnfrm\"+l_suffix\n",
    "    iMap_nd = \"imap_nd\"+l_suffix\n",
    "    model_points = \"model_points\"\n",
    "    model_positives = \"model\"+l_suffix # Unused name in the thresholdless version\n",
    "\n",
    "    whereClauses = { # SQL queries used to select records\n",
    "                # These will be set to negative integers\n",
    "                \"model-only_conf\": points+\" > 0 And \"+iMap_cnfrm+\" = 0\"+extras[0], \n",
    "                \"model-only_unconf\": points+\" > 0 And \"+iMap_cnfrm+\" = 0 And \"+iMap_uncnfrm+\" = 0\"+extras[0],\n",
    "                # These three will be set to 0\n",
    "                \"iMap-only_conf\": points+\" = 0 And (\"+iMap_cnfrm+\" > 0\"+extras[1], \n",
    "                \"iMap-only_unconf\": points+\" = 0 And (\"+iMap_cnfrm+\" > 0 Or \"+iMap_uncnfrm+\" > 0\"+extras[1],\n",
    "                # These three will be set to positive floats\n",
    "                \"Overlap_conf\": points+\" > 0 And (\"+iMap_cnfrm+\" > 0\"+extras[1], \n",
    "                \"Overlap_unconf\": points+\" > 0 And (\"+iMap_cnfrm+\" > 0 Or \"+iMap_uncnfrm+\" > 0\"+extras[1],\n",
    "                # Cells with neither record type will retain a null designation during calculation\n",
    "                }\n",
    "\n",
    "    if type == \"THRESHOLDED\": # Add extra conditions\n",
    "        whereClauses[\"model-only_nd\"] = model_points+\" > 0 And \"+model_points+\" > \"+model_positives+\" And \"+iMap_nd+\" = 0\"\n",
    "        whereClauses[\"iMap-only_nd\"] = model_points+\" = 0 And \"+iMap_nd+\" > 0\"\n",
    "        whereClauses[\"Overlap_nd\"] = model_points+\" > 0 And \"+model_points+\" > \"+model_positives+\" And \"+iMap_nd+\" > 0\"\n",
    "    \n",
    "    return(whereClauses) # Return dictionary of where clauses when called\n",
    "\n",
    "def generateCalcFieldDict(type): # Return a dictionary of fields to assign calculated value \n",
    "    fields_dict = generateWhereClauses(type) # Create a reference to the whereClause dict\n",
    "    \n",
    "    # Update dict entries with the values being the field where the value to be calculated later should be stored\n",
    "    if type == \"THRESHOLDED\":\n",
    "        s_suffix = \"_\"+species\n",
    "        for field in [\"model-only_nd\", \"iMap-only_nd\", \"Overlap_nd\"]:\n",
    "            fields_dict[field] = \"NDc\"+s_suffix\n",
    "    elif type == \"NOT_THRESHOLDED\":\n",
    "        s_suffix = \"_overall\"\n",
    "    for field in [\"model-only_conf\", \"iMap-only_conf\", \"Overlap_conf\"]:\n",
    "        fields_dict[field] = \"Cc\"+s_suffix\n",
    "    for field in [\"model-only_unconf\", \"iMap-only_unconf\", \"Overlap_unconf\"]:\n",
    "        fields_dict[field] = \"CUc\"+s_suffix\n",
    "    \n",
    "    return(fields_dict)\n",
    "\n",
    "def generateCalcExpressions(type): # Return a dictionary of expressions to calculate comparison values \n",
    "    exp_dict = generateWhereClauses(type) # Create reference to main whereClause dict\n",
    "    \n",
    "    if type == \"THRESHOLDED\":\n",
    "        l_suffix = \"_\"+species\n",
    "        points = \"!model\"+l_suffix+\"!\"\n",
    "        extra = \"\"\n",
    "    elif type == \"NOT_THRESHOLDED\":\n",
    "        l_suffix = \"\"\n",
    "        points = \"!model_points!\"\n",
    "        extra = \"+ !iMap_nd!\"\n",
    "        \n",
    "    # Generate proper layer names to reference in calculations \n",
    "    iMap_cnfrm = \"!imap_cnfrm\"+l_suffix+\"!\"\n",
    "    iMap_uncnfrm = \"!imap_uncnfrm\"+l_suffix+\"!\"\n",
    "    iMap_nd = \"!imap_nd\"+l_suffix+\"!\"\n",
    "    model_positives = \"!model\"+l_suffix+\"!\" # Unused name in the thresholdless version\n",
    "\n",
    "    # Update dictionary with the values being the expression used to calculate the field determined by generateCalcFieldDict()\n",
    "    for field in [\"model-only_conf\", \"model-only_unconf\"]:\n",
    "        exp_dict[field] = \"-\"+points\n",
    "    for field in [\"iMap-only_conf\", \"iMap-only_unconf\"]:\n",
    "        exp_dict[field] = \"0\"\n",
    "    exp_dict[\"Overlap_conf\"] = points+\"/(\"+iMap_cnfrm+extra+\")\" # Effectively, \"extra\" adds iMap_nd if thresholdless and doesn't for thresholded\n",
    "    exp_dict[\"Overlap_unconf\"] = points+\"/(\"+iMap_cnfrm+\" + \"+iMap_uncnfrm+extra+\")\" # Same effect as above line\n",
    "    if type == \"THRESHOLDED\":\n",
    "        exp_dict[\"iMap-only_nd\"] = \"0\"\n",
    "        exp_dict[\"model-only_nd\"] = \"-(!model_points! - \"+model_positives+\")\"\n",
    "        exp_dict[\"Overlap_nd\"] = \"(!model_points! - \"+model_positives+\")/\"+iMap_nd\n",
    "    \n",
    "    return(exp_dict)\n",
    "    \n",
    "# Create list of imap features to iterate over\n",
    "imap_data = list() # To be filled to include points, lines, polygons, and not detected\n",
    "geometries = [\"POINT\",\"LINE\",\"POLYGON\"]\n",
    "types = [\"CONFIRMED\",\"UNCONFIRMED\"]\n",
    "for geometry in geometries:\n",
    "    for record_type in types:\n",
    "        if record_type is \"CONFIRMED\":\n",
    "            imap_data.append(\"PRESENCE_\"+geometry)\n",
    "        else:\n",
    "            imap_data.append(\"PRESENCE_\"+geometry+\"_\"+record_type)\n",
    "imap_data.append(\"NOT_DETECTED_POLYGON\")\n",
    "\n",
    "print(\"iMap datasets:\")\n",
    "print(imap_data)\n",
    "\n",
    "# Create dictionary of long names\n",
    "# Names used for filtering in ArcGIS Online\n",
    "species_fullnames = {\n",
    "    \"phrag\": \"'Phragmites, Unspecified'\", # extra sinlge quotes are intentional since these are used in a field calculation\n",
    "    \"knot\": \"'Knotweed, Unspecified'\",\n",
    "    \"wp\": \"'Wild Parsnip'\",\n",
    "    \"toh\": \"'Tree-of-Heaven (Ailanthus)'\",\n",
    "    \"pl\": \"'Purple Loosestrife'\"\n",
    "}\n",
    "\n",
    "# Extract only the keys to a list\n",
    "species_shortnames = list(species_fullnames.keys())\n",
    "\n",
    "# IDs that iMap assigns to the various species of interest\n",
    "jurisdiction_ids = {\n",
    "    \"phrag\": 1277,\n",
    "    \"wp\": 1182,\n",
    "    \"pl\": 1265,\n",
    "    \"toh\": 1167,\n",
    "    \"knot\": (1074, 1191, 1278, 1479) # Includes Japanese knotweed, giant knotweed, bohemian knotweed, and knotweed species unknown\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Code to create a fishnet for the state if you do not already have one\n",
    "# aoi = ['4,481,032.099500 105,606.381800 4,985,489.904000 770,761.900100'] # New york state boundary coordinates in UTM Zone 18N projection (Coordinates are expressed in the order of x-min, y-min, x-max, y-max)\n",
    "# cellsize = '1' # The width and height argument for the fishnet function\n",
    "# fishnet_output_name = 'grid_nys_18N_1km'\n",
    "# # Create fishnet \n",
    "# arcpy.management.CreateFishnet(fishnet_output_name, '4,985,489.904000 105,606.381800', '4,481,032.099500 105,606.381800', cellsize, cellsize, '0', '0', {corner_coord}, 'NO_LABELS', aoi, 'POLYGON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Thresholdless Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joining iMap data\n",
      "***PRESENCE_POINT\n",
      "***PRESENCE_POINT_UNCONFIRMED\n",
      "***PRESENCE_LINE\n",
      "***PRESENCE_LINE_UNCONFIRMED\n",
      "***PRESENCE_POLYGON\n",
      "***PRESENCE_POLYGON_UNCONFIRMED\n",
      "***NOT_DETECTED_POLYGON\n",
      "Joining model data\n",
      "***pred_finalDeployment_all\n",
      "Copying final output\n",
      "Calculating total iMap features joined\n",
      "('!imap_point_cnfrm!', '!imap_line_cnfrm!', '!imap_poly_cnfrm!')\n",
      "['!imap_point_uncnfrm!', '!imap_line_uncnfrm!', '!imap_poly_uncnfrm!']\n",
      "Adding comparison fields\n",
      "Calculating comparison values\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# For thresholdless reporting analysis\n",
    "dataset_lists = [imap_data, model_pred]\n",
    "\n",
    "# Lists of fields to fill in later\n",
    "tmpCnfrm = list()\n",
    "tmpUncnfrm = list()\n",
    "\n",
    "tmpFeatures = list() # List of temp features to deleve later\n",
    "\n",
    "# Define target feature for first run\n",
    "targetFeature = \"reporting_analysis_grid_empty\"\n",
    "\n",
    "for datasets in dataset_lists:\n",
    "    if datasets is model_pred:\n",
    "        print(\"Joining model data\")\n",
    "    else:\n",
    "        print(\"Joining iMap data\")\n",
    "    for joinFeature in datasets:\n",
    "\n",
    "        # If model data ----------\n",
    "        if datasets is model_pred: \n",
    "\n",
    "            outFeature = \"tmpRAG_model\"\n",
    "            fieldName = \"model_points\"\n",
    "                \n",
    "        # If iMap data ----------    \n",
    "        else:\n",
    "        \n",
    "            # Define unique output names\n",
    "            if \"UNCONFIRMED\" in joinFeature:\n",
    "                if \"POINT\" in joinFeature:\n",
    "                    outFeature = \"tmpRAG_point_uncnfrm\"\n",
    "                    fieldName = \"imap_point_uncnfrm\"\n",
    "                if \"LINE\" in joinFeature:\n",
    "                    outFeature = \"tmpRAG_line_uncnfrm\"\n",
    "                    fieldName = \"imap_line_uncnfrm\"\n",
    "                if \"POLYGON\" in joinFeature:\n",
    "                    outFeature = \"tmpRAG_poly_uncnfrm\"\n",
    "                    fieldName = \"imap_poly_uncnfrm\"\n",
    "                tmpUncnfrm.append(\"!\"+fieldName+\"!\")\n",
    "            elif \"NOT_DETECTED\" in joinFeature:\n",
    "                outFeature = \"tmpRAG_nd\"\n",
    "                fieldName = \"iMap_nd\"\n",
    "            else:\n",
    "                if \"POINT\" in joinFeature:\n",
    "                    outFeature = \"tmpRAG_point_cnfrm\"\n",
    "                    fieldName = \"imap_point_cnfrm\"\n",
    "                if \"LINE\" in joinFeature:\n",
    "                    outFeature = \"tmpRAG_line_cnfrm\"\n",
    "                    fieldName = \"imap_line_cnfrm\"\n",
    "                if \"POLYGON\" in joinFeature:\n",
    "                    outFeature = \"tmpRAG_poly_cnfrm\"\n",
    "                    fieldName = \"imap_poly_cnfrm\"\n",
    "\n",
    "                # Add field to list for use in calculating later\n",
    "                tmpCnfrm.append(\"!\"+fieldName+\"!\")\n",
    "        \n",
    "        print(\"***\"+joinFeature)\n",
    "        fm = create_SJ_FieldMappings(targetFeature, joinFeature) # Create the field mappings for the join\n",
    "        arcpy.analysis.SpatialJoin(targetFeature, joinFeature, outFeature, \"JOIN_ONE_TO_ONE\", \"KEEP_ALL\", fm) # Count the features within each grid cell\n",
    "        \n",
    "        arcpy.management.AlterField(outFeature, \"JOIN_COUNT\", fieldName, fieldName) # Rename join_count field\n",
    "        arcpy.management.DeleteField(outFeature, \"TARGET_FID\") # Delete unnecessary field\n",
    "        \n",
    "        \n",
    "        tmpFeatures.append(outFeature) # Add feature to list to delete later\n",
    "        \n",
    "        targetFeature = outFeature # Make the output feature the input for the next join\n",
    "\n",
    "# Copy the final output feature that has all desired fields\n",
    "print(\"Copying final output\")\n",
    "RAG_tl = \"reporting_analysis_grid_thresholdless\"\n",
    "arcpy.management.CopyFeatures(outFeature, RAG_tl)\n",
    "\n",
    "# Calculate the total number of iMap features joined\n",
    "print(\"Calculating total iMap features joined\")\n",
    "\n",
    "cName = \"iMap_cnfrm\"\n",
    "uName = \"iMap_uncnfrm\"\n",
    "arcpy.management.AddFields(RAG_tl, [\n",
    "    [cName, 'SHORT'],\n",
    "    [uName, 'SHORT']\n",
    "])\n",
    "\n",
    "tmpCnfrm = tuple(tmpCnfrm)\n",
    "print(tmpCnfrm)\n",
    "arcpy.management.CalculateField(RAG_tl, cName, tmpCnfrm[0]+\"+\"+tmpCnfrm[1]+\"+\"+tmpCnfrm[2])\n",
    "print(tmpUncnfrm)\n",
    "tmpUncnfrm = tuple(tmpUncnfrm)\n",
    "arcpy.management.CalculateField(RAG_tl, uName, tmpUncnfrm[0]+\"+\"+tmpUncnfrm[1]+\"+\"+tmpUncnfrm[2])\n",
    "\n",
    "print(\"Adding comparison fields\")\n",
    "ccName = \"C_comp_overall\"\n",
    "cucName = \"CU_comp_overall\"\n",
    "\n",
    "arcpy.management.AddFields(RAG_tl, [\n",
    "    [ccName, 'FLOAT'],\n",
    "    [cucName, 'FLOAT']\n",
    "])\n",
    "\n",
    "print(\"Calculating comparison values\")\n",
    "type = \"NOT_THRESHOLDED\"\n",
    "fieldDict = generateCalcFieldDict(type)\n",
    "expDict = generateCalcExpressions(type)\n",
    "wCs = generateWhereClauses(type)\n",
    "\n",
    "for key in wCs: # Loop to calculate the reporting analysis values\n",
    "    sel = arcpy.management.SelectLayerByAttribute(RAG_tl, \"NEW_SELECTION\", wCs[key]) # Make the selection\n",
    "    arcpy.management.CalculateField(sel, fieldDict[key], expDict[key]) # Calculate values in field based on expression\n",
    "    del sel\n",
    "\n",
    "for field_list in [tmpCnfrm, tmpUncnfrm]:\n",
    "    arcpy.management.DeleteField(RAG_tl, field_list) # Delete per-geometry fields that are no longer needed\n",
    "    \n",
    "del type, fieldDict, expDict, wCs\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete temporary files\n",
    "# This way is necessary to delete the feature itself and not just its contents\n",
    "import os\n",
    "cws = arcpy.env.workspace\n",
    "\n",
    "# Delete unmerged presence points\n",
    "for input in tmpFeatures:\n",
    "  input_path = os.path.join(cws, input)\n",
    "  if arcpy.Exists(input_path):\n",
    "    arcpy.Delete_management(input_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Species-Based Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this if running for different thresholds\n",
    "\n",
    "# Define the threshold used to determine presences\n",
    "# Used as a suffix and as a field in the viewing version of the final layer\n",
    "threshold = 'precision'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers to process: 40\n",
      "['SVI_Project_presences_phrag_precision', 'SVI_Project_presences_knot_precision', 'SVI_Project_presences_wp_precision', 'SVI_Project_presences_toh_precision', 'SVI_Project_presences_pl_precision', 'iMap_nd_phrag', 'iMap_point_cnfrm_phrag', 'iMap_line_cnfrm_phrag', 'iMap_polygon_cnfrm_phrag', 'iMap_point_uncnfrm_phrag', 'iMap_line_uncnfrm_phrag', 'iMap_polygon_uncnfrm_phrag', 'iMap_nd_knot', 'iMap_point_cnfrm_knot', 'iMap_line_cnfrm_knot', 'iMap_polygon_cnfrm_knot', 'iMap_point_uncnfrm_knot', 'iMap_line_uncnfrm_knot', 'iMap_polygon_uncnfrm_knot', 'iMap_nd_wp', 'iMap_point_cnfrm_wp', 'iMap_line_cnfrm_wp', 'iMap_polygon_cnfrm_wp', 'iMap_point_uncnfrm_wp', 'iMap_line_uncnfrm_wp', 'iMap_polygon_uncnfrm_wp', 'iMap_nd_toh', 'iMap_point_cnfrm_toh', 'iMap_line_cnfrm_toh', 'iMap_polygon_cnfrm_toh', 'iMap_point_uncnfrm_toh', 'iMap_line_uncnfrm_toh', 'iMap_polygon_uncnfrm_toh', 'iMap_nd_pl', 'iMap_point_cnfrm_pl', 'iMap_line_cnfrm_pl', 'iMap_polygon_cnfrm_pl', 'iMap_point_uncnfrm_pl', 'iMap_line_uncnfrm_pl', 'iMap_polygon_uncnfrm_pl']\n"
     ]
    }
   ],
   "source": [
    "# Separate out iMap records by species and geometry ----------\n",
    "\n",
    "# Add model data layer names to processing list ----------\n",
    "\n",
    "\n",
    "# Create list of n + n*3 files to process, where n is the number of species\n",
    "ps_records = [] # empty list to append items onto\n",
    "\n",
    "# Add names to list\n",
    "for n in range(0,len(species_shortnames)):\n",
    "    # Add n items for model data \n",
    "    ps_records.append('SVI_Project_presences_'+species_shortnames[n]+\"_\"+threshold)\n",
    "\n",
    "    \n",
    "# ----------\n",
    "\n",
    "# Define list of geometries in the iMap data\n",
    "imap_geometries = [\"POINT\", \"LINE\", \"POLYGON\"]\n",
    "\n",
    "# Define imap records types\n",
    "imap_record_types = {\n",
    "    \"cnfrm\": \"_Conf\", # The \"suffix\" for confirmed records is blank\n",
    "    \"uncnfrm\": \"_Unconf\"\n",
    "}\n",
    "\n",
    "# Add n*2*3 + n items for iMap data (accounts for 2 record and 3 geometry types, \n",
    "# plus not-detected records) \n",
    "for n in range(0,len(species_shortnames)):\n",
    "    # Set up per-species query for selecting by attribute\n",
    "    if species_shortnames[n] is \"knot\":\n",
    "        # Set initial SQL query\n",
    "        idClause = \"jurisdiction_species_id = \"+str(jurisdiction_ids[\"knot\"][0])\n",
    "        # Add more conditions to query\n",
    "        for ID in jurisdiction_ids[\"knot\"][1:]:\n",
    "            idClause = idClause + \" Or jurisdiction_species_id = \" + str(ID)\n",
    "    else:\n",
    "        idClause = \"jurisdiction_species_id = \"+str(jurisdiction_ids[species_shortnames[n]]) \n",
    "    \n",
    "    # Copy a per-species subset of not detected polygons\n",
    "    sel = arcpy.management.SelectLayerByAttribute(\"NOT_DETECTED_POLYGON\", \"NEW_SELECTION\", idClause)\n",
    "    imap_nd = \"iMap_nd_\"+species_shortnames[n]\n",
    "    arcpy.management.CopyFeatures(sel, imap_nd)\n",
    "    ps_records.append(imap_nd)\n",
    "    # Remove variables and selections to save memory\n",
    "    del sel, imap_nd\n",
    "    arcpy.management.SelectLayerByAttribute(\"NOT_DETECTED_POLYGON\", \"CLEAR_SELECTION\")\n",
    "    \n",
    "    # Copy a per-species subset for each record and geometry type\n",
    "    for rt in range(0,len(imap_record_types)):\n",
    "        if rt == 0: # Confirmed\n",
    "            rt_suffix = \"\"\n",
    "        elif rt == 1: # Unconfirmed\n",
    "            rt_suffix = \"_UNCONFIRMED\"\n",
    "        for g in range(0,len(imap_geometries)):\n",
    "            sel = arcpy.management.SelectLayerByAttribute(\"PRESENCE_\"+imap_geometries[g]+rt_suffix, \"NEW_SELECTION\", idClause)\n",
    "            imap_subset = \"iMap_\"+imap_geometries[g].lower()+\"_\"+list(imap_record_types.keys())[rt]+\"_\"+species_shortnames[n]\n",
    "            arcpy.management.CopyFeatures(sel, imap_subset)\n",
    "            ps_records.append(imap_subset)\n",
    "            # Remove variables and selections to save memory\n",
    "            del sel, imap_subset\n",
    "            arcpy.management.SelectLayerByAttribute(\"PRESENCE_\"+imap_geometries[g], \"CLEAR_SELECTION\")\n",
    "        \n",
    "        \n",
    "# ----------\n",
    "\n",
    "print(\"Number of layers to process: \"+str(len(ps_records)))\n",
    "print(ps_records)\n",
    "\n",
    "del imap_geometries, imap_record_types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create analysis-ready version (1 layer with fields for all species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_phrag\n",
      "model_knot\n",
      "model_wp\n",
      "model_toh\n",
      "model_pl\n",
      "iMap_nd_phrag\n",
      "iMap_point_cnfrm_phrag\n",
      "iMap_line_cnfrm_phrag\n",
      "iMap_polygon_cnfrm_phrag\n",
      "iMap_point_uncnfrm_phrag\n",
      "iMap_line_uncnfrm_phrag\n",
      "iMap_polygon_uncnfrm_phrag\n",
      "iMap_nd_knot\n",
      "iMap_point_cnfrm_knot\n",
      "iMap_line_cnfrm_knot\n",
      "iMap_polygon_cnfrm_knot\n",
      "iMap_point_uncnfrm_knot\n",
      "iMap_line_uncnfrm_knot\n",
      "iMap_polygon_uncnfrm_knot\n",
      "iMap_nd_wp\n",
      "iMap_point_cnfrm_wp\n",
      "iMap_line_cnfrm_wp\n",
      "iMap_polygon_cnfrm_wp\n",
      "iMap_point_uncnfrm_wp\n",
      "iMap_line_uncnfrm_wp\n",
      "iMap_polygon_uncnfrm_wp\n",
      "iMap_nd_toh\n",
      "iMap_point_cnfrm_toh\n",
      "iMap_line_cnfrm_toh\n",
      "iMap_polygon_cnfrm_toh\n",
      "iMap_point_uncnfrm_toh\n",
      "iMap_line_uncnfrm_toh\n",
      "iMap_polygon_uncnfrm_toh\n",
      "iMap_nd_pl\n",
      "iMap_point_cnfrm_pl\n",
      "iMap_line_cnfrm_pl\n",
      "iMap_polygon_cnfrm_pl\n",
      "iMap_point_uncnfrm_pl\n",
      "iMap_line_uncnfrm_pl\n",
      "iMap_polygon_uncnfrm_pl\n",
      "All done\n"
     ]
    }
   ],
   "source": [
    "# Spatial join repeatedly\n",
    "RAG_tl = \"reporting_analysis_grid_thresholdless\" # Defined a few cells above\n",
    "input_grid = RAG_tl\n",
    "\n",
    "import os # For deleting intermediate spatial joins\n",
    "\n",
    "tmpFeatures = list()\n",
    "\n",
    "# Used for tracking iterations which enables field calculations to be performed after \n",
    "# confirmed and unconfirmed iMap records of all geometries are spatially joined\n",
    "counter = 1\n",
    "\n",
    "# Effectively, for iMap and model data, each species, and geometry/record type (if iMap data):\n",
    "for i, r in enumerate(ps_records):\n",
    "    # Define field naming convention\n",
    "    if \"SVI\" in r:\n",
    "        # Slice to only retain the species and create new field name\n",
    "        species = r[22:-10]\n",
    "        field_name = \"model_\"+species\n",
    "    else:\n",
    "        field_name = r\n",
    "\n",
    "    print(field_name)\n",
    "\n",
    "    fm = create_SJ_FieldMappings(input_grid, r) # Create the field mappings for this join\n",
    "\n",
    "    # Perform the spatial join & clean the table ----------\n",
    "\n",
    "    out_grid = \"tmp_grid_\"+str(i)\n",
    "    tmpFeatures.append(out_grid) # add to list for deleting later\n",
    "    arcpy.analysis.SpatialJoin(input_grid,r,out_grid,\"JOIN_ONE_TO_ONE\",\"KEEP_ALL\",fm)\n",
    "    del fm\n",
    "\n",
    "    # Rename Join_Count field\n",
    "    arcpy.management.AlterField(out_grid, \"Join_Count\", field_name, field_name)\n",
    "    # Delete TARGET_FID field\n",
    "    arcpy.management.DeleteField(out_grid, \"TARGET_FID\")\n",
    "\n",
    "    # ----------\n",
    "\n",
    "\n",
    "    # Sum records only after confirmed or unconfirmed iMap records of all geometries are spatially joined ----------\n",
    "\n",
    "    if i >= len(species_shortnames): # If our iteration index is past processing model data\n",
    "        \n",
    "\n",
    "        # Determine the oscillation\n",
    "        if \"nd\" in r:\n",
    "            x = 4\n",
    "        elif \"point_uncnfrm\" in r:\n",
    "            x = 3\n",
    "\n",
    "\n",
    "        # Effectively oscillate between running every 4th and 3rd entry, respectively \n",
    "        if (counter == x): # If the counter is at the oscillating xth entry we're targeting\n",
    "            counter = 0 # Reset the count\n",
    "\n",
    "            sum_fields = ps_records[i-2:i+1] # Select three fields of interest to sum\n",
    "            sum_name = \"iMap_\"+r[13:] # Create desired field name\n",
    "            express = \"!\"+sum_fields[0]+\"!+!\"+sum_fields[1]+\"!+!\"+sum_fields[2]+\"!\" # Create expression for calculating sum \n",
    "            arcpy.management.AddField(out_grid, sum_name, \"SHORT\") # Create the field\n",
    "            arcpy.management.CalculateField(out_grid,sum_name,express) # Sum the fields\n",
    "            for field in sum_fields: # Loop through the fields used when summing\n",
    "                arcpy.management.DeleteField(out_grid, field) # Delete the field from the feature since they're no longer necessary\n",
    "\n",
    "        counter += 1 # Add 1 to the count\n",
    "\n",
    "    # ----------\n",
    "\n",
    "\n",
    "    input_grid = \"tmp_grid_\"+str(i) # Make the next run's target grid the output of this iteration's spatial join\n",
    "\n",
    "    if i == len(ps_records)-1: # If the last iteration\n",
    "        RAG_final = \"SVI_Proj_reporting_analysis_grid_1km\"\n",
    "        arcpy.management.CopyFeatures(out_grid, RAG_final) # copy to a new feature\n",
    "        \n",
    "        del counter, input_grid, out_grid\n",
    "\n",
    "# Delete temporary files\n",
    "# This way is necessary to delete the feature itself and not just its contents\n",
    "cws = arcpy.env.workspace\n",
    "\n",
    "# Delete unmerged presence points\n",
    "for input in tmpFeatures:\n",
    "  input_path = os.path.join(cws, input)\n",
    "  if arcpy.Exists(input_path):\n",
    "    arcpy.Delete_management(input_path)\n",
    "    \n",
    "del tmpFeatures\n",
    "    \n",
    "print(\"All done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding comparison fields\n",
      "Calculating comparison values\n",
      "Adding comparison fields\n",
      "Calculating comparison values\n",
      "Adding comparison fields\n",
      "Calculating comparison values\n",
      "Adding comparison fields\n",
      "Calculating comparison values\n",
      "Adding comparison fields\n",
      "Calculating comparison values\n",
      "Analysis version of the reporting gap analysis complete\n"
     ]
    }
   ],
   "source": [
    "# Calculate per-species ND ratios, confirmed ratios, unconfirmed ratios, and rato percentiles\n",
    "\n",
    "from scipy.stats import percentileofscore # For calculating the percentile of each value\n",
    "import pandas as pd\n",
    "\n",
    "# RAG_final = \"SVI_Proj_reporting_analysis_grid_1km\" # Defined a cell above\n",
    "\n",
    "for species in species_shortnames:\n",
    "    print(\"Adding comparison fields\")\n",
    "    ccName = \"Cc_\"+species\n",
    "    cucName = \"CUc_\"+species\n",
    "    ndcName = \"NDc_\"+species\n",
    "    arcpy.management.AddFields(RAG_final, [\n",
    "        [ccName, 'FLOAT'],\n",
    "        [cucName, 'FLOAT'],\n",
    "        [ndcName, 'FLOAT']\n",
    "    ])\n",
    "\n",
    "    print(\"Calculating comparison values\")\n",
    "    type = \"THRESHOLDED\"\n",
    "    fieldDict = generateCalcFieldDict(type)\n",
    "    expDict = generateCalcExpressions(type)\n",
    "    wCs = generateWhereClauses(type)\n",
    "\n",
    "    a = len(fieldDict)\n",
    "    b = len(expDict)\n",
    "    c = len(wCs)\n",
    "    \n",
    "    if a == b and b == c:\n",
    "        pass\n",
    "    else:\n",
    "        print(\"Error in key names of one or more of fieldDict, expDict, and wCs\")\n",
    "        quit()\n",
    "\n",
    "    for key in wCs: # Loop to calculate the reporting analysis values\n",
    "        sel = arcpy.management.SelectLayerByAttribute(RAG_final, \"NEW_SELECTION\", wCs[key]) # Make the selection\n",
    "        arcpy.management.CalculateField(sel, fieldDict[key], expDict[key]) # Calculate values in field based on expression\n",
    "        del sel\n",
    "\n",
    "    del type, fieldDict, expDict, wCs\n",
    "\n",
    "    # Calculate percentile field that describes the percentile of model-only record magnitude and imap-model overlap ratio ----------\n",
    "    \n",
    "\n",
    "    import scipy\n",
    "    from scipy.stats import percentileofscore # For calculating the percentile of each value\n",
    "\n",
    "    # Calculate percentile field that describes the percentile of model-only record magnitude or imap-model overlap ratio ----------\n",
    "\n",
    "    filters = [\" < 0\", \" > 0\"]\n",
    "    comp_types = [\"Cc_\", \"CUc_\", \"NDc_\"]\n",
    "\n",
    "    for comp_type in comp_types: # For each comparison type (Confirmed, Unconfirmed, Not detected)\n",
    "        ratio_field = comp_type+species\n",
    "        pct_field = \"pct_\"+ratio_field\n",
    "\n",
    "        arcpy.management.AddField(RAG_final, pct_field, \"FLOAT\")\n",
    "\n",
    "        for filter in filters: # For (effectively) both the overlap and model-only sets\n",
    "            rga_values = [abs(row.getValue(ratio_field)) for row in arcpy.SearchCursor(RAG_final, ratio_field+filter)] # Return a list of all reporting gap analysis magnitudes (only positives or negatives, no nulls)\n",
    "            cursor = arcpy.UpdateCursor(RAG_final, ratio_field+filter)\n",
    "            \n",
    "            if filter is \" < 0\":\n",
    "                x = -1 # Make model-only percentiles negative\n",
    "            else:\n",
    "                x = 1 # Keep overlap percentiles positive\n",
    "            \n",
    "            for i, row in enumerate(cursor): # For each row in the filtered dataset\n",
    "                pct_v = x*scipy.stats.percentileofscore(rga_values, abs(row.getValue(ratio_field))) # Calculate the percentile of the reporting gap analysis value\n",
    "        #         if i < 20: # View the first 20 ratio and percentile values\n",
    "        #             print(\"r \",abs(row.getValue(ratio_field)))\n",
    "        #             print(\"p \",pct_v)\n",
    "                row.setValue(pct_field, pct_v) # Assign the percentile of that reporting gap analysis value\n",
    "                cursor.updateRow(row) # As far as I understand, this locks in that edit\n",
    "                del pct_v\n",
    "                \n",
    "            del rga_values, cursor\n",
    "\n",
    "        # Add zeroes to cells where there's only iMap data\n",
    "        cursor = arcpy.UpdateCursor(RAG_final, ratio_field+\" = 0\")\n",
    "        for row in cursor:\n",
    "            row.setValue(pct_field, 0)\n",
    "            cursor.updateRow(row)\n",
    "        del cursor\n",
    "        \n",
    "\n",
    "    # ----------\n",
    "del filters\n",
    "print(\"Analysis version of the reporting gap analysis complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the viewing-ready version (1 layer with combined comp and pct fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section pseudocode\n",
    "# For each species:\n",
    "    # Select records with non-null values for that species\n",
    "    # Copy to new feature\n",
    "    # Collapse per-species ratio and percentile fields into two new ones \n",
    "    # Delete per-species ratio and percentile fields\n",
    "    # Add & calculate common name, jurisdiction id, and op criteria fields\n",
    "# Merge layers into one for upload into AGOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Viewing layer of the reporting gap analysis complete\n"
     ]
    }
   ],
   "source": [
    "merge_sets = list() # Updated to contain the per-species layers to merge\n",
    "\n",
    "for species in species_shortnames: # For each species\n",
    "    whereClause = \"\"\n",
    "    # Create where clause used to select cells where there are records\n",
    "    for i, comp_type in enumerate(comp_types):\n",
    "        ratio_field = comp_type+species\n",
    "        \n",
    "        if i < 1:\n",
    "            whereClause = ratio_field + \" IS NOT NULL\"\n",
    "        else: \n",
    "            whereClause = whereClause + \" or \" + ratio_field + \" IS NOT NULL\"\n",
    "        del ratio_field\n",
    "\n",
    "    sel = arcpy.management.SelectLayerByAttribute(RAG_final, \"NEW_SELECTION\", whereClause) # Select cells where there are records\n",
    "    \n",
    "    ps_viewing_layer = \"tmp_ps_view_\"+species\n",
    "    arcpy.management.CopyFeatures(sel, ps_viewing_layer) # Create a copy of records for just this species\n",
    "    merge_sets.append(ps_viewing_layer) # Add to list for merging later\n",
    "\n",
    "    \n",
    "    for comp_type in comp_types:\n",
    "        ratio_field = comp_type+species\n",
    "        pct_field = \"pct_\"+ratio_field\n",
    "        \n",
    "        # Collapse per-species field values into two fields\n",
    "        arcpy.management.CalculateField(ps_viewing_layer, comp_type+\"ps\", \"!\"+ratio_field+\"!\")\n",
    "        arcpy.management.CalculateField(ps_viewing_layer, comp_type+\"ps_pct\", \"!\"+pct_field+\"!\")\n",
    "\n",
    "        arcpy.management.DeleteField(ps_viewing_layer, [ratio_field, pct_field]) # Delete per-species fields\n",
    "    \n",
    "    # Add some attribute fields to enable filtering in the ArcGIS Online dashboard\n",
    "    arcpy.management.CalculateField(ps_viewing_layer, \"Common_Nam\", species_fullnames[species])\n",
    "    if species is \"knot\":\n",
    "        jsid = 1479 # Knotweed unspecified\n",
    "    else:\n",
    "        jsid = jurisdiction_ids[species]\n",
    "    arcpy.management.CalculateField(ps_viewing_layer, \"jurisdiction_species_id\", jsid)\n",
    "    arcpy.management.CalculateField(ps_viewing_layer, \"op_criteria\", \"'\"+threshold+\"'\")\n",
    "\n",
    "arcpy.management.Merge(merge_sets, \"SVI_Proj_RAG_1km_Viewing\")\n",
    "\n",
    "print(\"Viewing layer of the reporting gap analysis complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete temporary files\n",
    "# This way is necessary to delete the feature itself and not just its contents\n",
    "cws = arcpy.env.workspace\n",
    "\n",
    "import os\n",
    "tmpFeatures = list()\n",
    "for species in species_shortnames:\n",
    "    tmpFeatures.append(\"tmp_ps_view_\"+species) # Add per-species layers\n",
    "    tmpFeatures.append(\"iMap_nd_\"+species) # Add iMap not-detected\n",
    "    for rt in ['cnfrm', 'uncnfrm']:\n",
    "        for geometry in ['point', 'line', 'polygon']:\n",
    "            tmpFeatures.append(\"iMap_\"+geometry+\"_\"+rt+\"_\"+species) # Add iMap polygon\n",
    "    \n",
    "# Delete unmerged presence points\n",
    "for input in tmpFeatures:\n",
    "  input_path = os.path.join(cws, input)\n",
    "  if arcpy.Exists(input_path):\n",
    "    arcpy.Delete_management(input_path)\n",
    "\n",
    "# Delete user-defined variables\n",
    "for obj in dir():\n",
    "    if not obj.startswith(\"__\"): # If not a system var\n",
    "        del globals()[obj] # Delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3"
  },
  "vscode": {
   "interpreter": {
    "hash": "8f58821842ebfdc7cbfe1f42095cc50c88f3bb71d7cdf4c3472b8320885a5152"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
